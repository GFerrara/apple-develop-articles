<html>
<head>
<!-- Article ID: 7 - Extracted from develop-1992 -->
<!-- on 2024-01-22 by Giorgio Ferrara - giorgio<dot>ferrara<at>gmail<dot>com -->
<!-- The content is protected by copyright of their respective owners -->
<title>Winter 92 - THE VETERAN NEOPHYTE</title>
<link href="styles/main.css" rel="stylesheet" type="text/css">
</head>
<body>
<h2>THE VETERAN NEOPHYTE</h2>
<h2>SILICON SURPRISE</h2>
<h1>DAVE JOHNSON</h1>
<p>
<img src="img/132.gif" width="371 px"></img>
</p>
<p>
&nbsp;Many of the things that are important, many of the phenomena that drive the world,<br>
are based on very simple rules. Huge numbers of independent entities interacting in a<br>
simple way at their local level can exhibit surprisingly complex behavior. The<br>
amazing and endlessly fascinating thing is that the end result is not at all obvious if<br>
you look only at the local rules. 
</p>
<p>
&nbsp;Weather, for instance: get a bunch--and I mean<i>lots</i> --of gas molecules and water<br>
vapor together, and weather just happens (I've heard that really big closed buildings,<br>
like hangars and roofed stadiums, experience "weather" inside). As far as the<br>
molecules are concerned, there's no such thing as weather; they just sort of bump<br>
around and interact with their neighbors, and the result is wind, or clouds, or rain. 
</p>
<p>
&nbsp;Another good example is evolution (one of my favorite topics): throw a bunch of<br>
replicating things into an environment with limited but necessary (for replication)<br>
resources, and evolution just happens. As far as the replicators are concerned, there's<br>
no such thing as evolution; they simply do their best to replicate, and the result is<br>
trees, or dogs, or us. 
</p>
<p>
&nbsp;Chemistry is another example that comes to mind: throw a bunch of atoms together,<br>
and chemistry just happens. Again, as far as the atoms are concerned, there's no such<br>
thing as chemistry; they simply attract and repel each other, sticking together or<br>
flying apart, swapping electrons around, and the result is diamonds, or dynamite, or<br>
rust. 
</p>
<p>
&nbsp;The examples go on and on, you can find them almost anywhere you care to look.<br>
Scientists call it "emergent behavior": simple, local rules, repeated ad infinitum (in<br>
time, or space, or even some other dimension), surprisingly often produce behavior<br>
that's unexpected, even unpredictable, from just the rules. One of the things I like so<br>
much about computers is that they're superlative tools for exploring emergent<br>
behavior. 
</p>
<p>
&nbsp;There are three things in particular that make computers so good for this task: they<br>
can do arithmetic unsupervised, once they're told what to do; they can do their<br>
arithmetic inside a logical structure; and they can do it<i>really fast.&nbsp;&nbsp;</i> This combination<br>
is extremely powerful and, more important, is unique to computers. Before<br>
computers, no one ever saw good pictures of fractals-- though a few mathematicians<br>
knew they were there--and the reason is simply that no one had the patience to slog<br>
through the incredibly tedious, repetitive arithmetic needed to generate pictures of<br>
them. Computers allowed mathematicians to write a recipe for the math, and then just<br>
wait a little while for the results.&nbsp;&nbsp;&nbsp;In this sense, computers are a kind of microscope<br>
that allows people to see certain things<i>for the very first time. </i>
</p>
<p>
&nbsp;Today there's a huge and burgeoning branch of research, often and aptly termed the<br>
"sciences of complexity," that has only become possible with the aid of computers.<br>
Emergent behavior is just one aspect of this larger field. The study of complexity is<br>
suggesting all kinds of brand-new approaches in long-established fields. Medicine,<br>
sociology, psychology, economics, biology, neuroscience, mathematics, physics--all<br>
have been affected. Computers have also given rise to completely new fields of inquiry:<br>
artificial intelligence, artificial life, chaos theory, neural networks, genetic<br>
algorithms, even the study of computation itself. The list of applications and<br>
repercussions seems to be endless. 
</p>
<p>
It's amazing to me still, and probably always will be, that doing arithmetic inside a<br>
logical structure is a necessary<i>and sufficient</i> condition to simulate anything that can<br>
be described precisely. (Even things that can't be described precisely can be<br>
"precisely approximated"; a fact that makes engineers rejoice but mathematicians<br>
gag.) Simply doing arithmetic very fast and automatically produces a blazing, frothing<br>
torrent of diversity, a veritable fire hose of creation. 
</p>
<p>
What's even more fascinating to me is that computers themselves are beginning to<br>
exhibit many of the properties that characterize complex systems, including<br>
emergence. All they do, really, is arithmetic. (Of course, if you want to get down deep,<br>
all they do is shove electrons around, but that's a little too abstract, even for me.) But<br>
look at all the things computers are used for today, and think of all the things they<i>could</i><br>
be used for. Admittedly, this progression and diversification is driven by humans--it<br>
wouldn't happen without us--but the number and variety of computers and software<br>
that exist have arisen without a grand design, without an overall plan. It has truly<br>
begun to evolve. 
</p>
<p>
Early computer programs directly reflected the computer's capabilities. Most were<br>
basically number crunchers, since at heart the computer is a number cruncher.<br>
Computers were, after all, invented to do long, time-consuming calculations quickly<br>
and automatically (it helps a lot during wartime). And that's<i>still</i>&nbsp;&nbsp;all they do, but the<br>
programs have changed dramatically. 
</p>
<p>
Programmers soon began to abstract their programs away from sheer<br>
arithmetic--and thus from the machine--and began to use the arithmetic to simulate<br>
other things, both strange and ordinary. Word processing, computer graphics,<br>
spreadsheets, databases: all these arrived on the scene. There was (and still is) a wild<br>
divergence away from simply doing arithmetic. In theory, according to mathematical<br>
proofs, computers can simulate<i>any</i> logical system. There are certainly plenty of<br>
logical systems to go around, and plenty more to invent. 
</p>
<p>
So the progress of computing is a kind of human-driven evolution, with human use<br>
being the "fitness function" (that is, the function that determines how well a<br>
particular entity is doing). Humans also drive the mutation and recombination, since<br>
they're the ones inventing and modifying programs. And that's where programmers<br>
come into the picture. If we're dealing with an evolutionary process, and we want it to<br>
continue as fast as possible (we do, don't we?), we should provide the things that drive<br>
evolution most strongly: diversity, large numbers, and strong selection pressure.
</p>
<p>
Selection pressure is amply provided by the marketplace; applications that aren't<br>
useful, or are too expensive or buggy, die quick ignominious deaths. The large numbers<br>
that we need are already there, and getting larger. We can help increase them by<br>
moving away from the current tendency toward huge, multipurpose, feature-crammed<br>
applications and trying to get closer to the concept of independent, single-purpose<br>
tools. (Besides, small programs are easier to develop, easier to support, and easier for<br>
people to learn.)
</p>
<p>
This "granulation" also helps increase diversity, in that it breaks up the different<br>
functions of an application into independent entities, with "lives" of their own. But<br>
even more effective at increasing diversity is thinking of new things. Only by trying<br>
new stuff, by constantly exploring the landscape of possibilities, by endlessly<br>
diversifying, do we make progress. Today's applications are only the tiniest subset of<br>
what's possible.
</p>
<p>
Admittedly, there are very real practical limits: computers are only so fast (so far);<br>
developers need to make a living, so their programs have to sell (excepting, of course,<br>
those of you lucky enough to work in research and academia: you can't use this excuse);<br>
and, probably most important, programming computers well turns out to be<i>really</i><br>
<i>hard!&nbsp;&nbsp;</i> But none of these limits are insurmountable. Computers are getting faster at an<br>
incredible rate, new markets are opening up as the number and diversity of computer<br>
users increase, and programming is getting easier. (Obviously the joy of programming<br>
has very little to do with the mechanics of communicating with the machine: just look<br>
at all the assembly hackers and UNIX folks in the world. Come to think of it, maybe a<br>
lot of the fun is figuring out how to say what you want with a painfully limited<br>
vocabulary.)
</p>
<p>
A characteristic trait of complex systems is their sensitive dependence on initial<br>
conditions. Ask any meteorologist. A tiny whisper of change can cascade into a complete<br>
transformation of the system.&nbsp;&nbsp;&nbsp;The evolution of computing is careening along at a very<br>
high speed, with a lot of inertia, and in a lot of directions; but a gentle shove in just<br>
the right place might profoundly affect the outcome. Where's the right place to push?<br>
If I knew, I wouldn't be working for a living. But if we all just start pushing<br>
everywhere we can think of, as often as we can, then we're helping computing reach its<br>
next incarnation, whatever<i>that</i>&nbsp;&nbsp;may be. I can't wait to find out. 
</p>
<p>
<b>RECOMMENDED READING</b>
</p>
<ul>
<li><i>Artificial Life,</i>  edited by Christopher G. Langton (Addison-Wesley,<br>
1989).</li>
<li><i>Chaos </i> by James Gleick (Penguin Books, 1987).</li>
<li><i>Great Mambo Chicken and the Trans-Human Condition</i>  by Ed Regis<br>
(Addison-Wesley, 1990).</li>
<li><i>The Tenth Good Thing About Barney</i>  by Judith Viorst (Atheneum, 1971).</li>
</ul>
<p>
<b>DAVE JOHNSON </b>once spent the better part of a day at the public library researching<br>
rock skipping (a.k.a. gerplunking or dapping). He found two official organizations, one<br>
annual event, and a handful of articles in various magazines. Although he sent very<br>
nice letters to the organizations asking for further information, he never heard from<br>
them. The currently recognized world record is 29 skips. Rock skipping is still poorly<br>
understood by scientists. *
</p>
<p>
<b>Dave welcomes feedback </b>on his musings. He can be reached at JOHNSON.DK on<br>
AppleLink, dkj@apple.com on the Internet, or 75300,715 on CompuServe.*
</p>
</body>
</html>
