<!DOCTYPE html>
<html>
<head>
<!-- Article ID: 29 - Extracted from develop-1992 -->
<!-- on 2024-01-22 by Giorgio Ferrara - giorgio<dot>ferrara<at>gmail<dot>com -->
<!-- The content is protected by the copyright of its respective owners -->
<title>August 92 - THE VETERAN NEOPHYTE</title>
<link href="../common/styles/main.css" rel="stylesheet" type="text/css">
</head>
<body>
<h2>THE VETERAN NEOPHYTE</h2>
<h2>QUANTUM LUNCH</h2>
<h1>DAVE JOHNSON, WITH MICHAEL GREENSPON</h1>
<p>
<img src="img/208.gif" width="216 px"></img>
</p>
<p>
<i>I've just read the book Alan Turing: The Enigma, by Andrew Hodges, an outstanding and</i><br>
<i>profound-- if thick-- biography of Alan Turing. Turing's work touched on some deep</i><br>
<i>philosophical questions about the relationship between brains and computers. I</i><br>
<i>naturally had my own opinions, but I wanted to talk to somebody with more knowledge</i><br>
<i>of brains who was also computer savvy--someone with a foot in both worlds. So I paid</i><br>
<i>a visit to Michael Greenspon, who develops software models of neural systems with</i><br>
<i>Walter Freeman at UC Berkeley. We got together for lunch and had a very interesting</i><br>
<i>conversation. Here's a sample:</i>
</p>
<p>
[Audio embellishment: clinking of nice glassware as Dave and Michael dine in the sun]
</p>
<p>
<b>DKJ:</b> I heard something recently that struck me as profound: computers don't<br>
manipulate reality, they manipulate<i>representations</i> of reality. The profound part is<br>
that seems to be what brains do, too.&nbsp;&nbsp;&nbsp;Alan Turing, for much of his life, wanted to build<br>
a brain. He firmly believed that consciousness was caused only by the operation of the<br>
brain, and that the brain's operation could eventually be described at any level of<br>
detail.
</p>
<p>
[Michael looks patiently skeptical, but Dave plunges ahead, oblivious, waving his fork<br>
excitedly.] Further, he had previously proven that in principle, a "universal<br>
machine," of which the computer is a finite approximation, could simulate any other<br>
logical machine, and thus any logical process whatsoever. So if you could describe the<br>
function of the brain as a logical process, you should be able to program a computer to<br>
"be" a brain. The description part, of course, is the killer. But I can't help thinking<br>
that we'll get there eventually. What do you think? 
</p>
<p>
<b>MCG:</b> Whoa, Dave [almost choking on his exotic Thai salad], I think you've hit the<br>
intellectual cul- de-sac of traditional artificial intelligence. The reason it's so hard to<br>
describe the operation of the brain as a logical process is simple: it isn't a logical<br>
process at all. That's a cerebral approach to a fundamentally biological and physical<br>
problem. I'm sure someday we'll be able to logically explain the operation of the brain<br>
in terms of physics, but that explanation won't include a computational mechanics<br>
based on formal logical operations.
</p>
<p>
<b>DKJ:</b> But then how do you approach the problem of trying to understand and model<br>
brains in your lab, if you can't describe them as logical processes? 
</p>
<p>
<b>MCG:</b> Our approach is that of computational neuroscience; we're doing dynamic<br>
modeling at the level of cell populations, using massively parallel machines with a<br>
Macintosh front end. 
</p>
<p>
When I say representationalist AI is a cerebral approach, it helps to realize that the<br>
cerebral cortex is just a few millimeters thin. It's a tissue essential for generating the<br>
separatist intellectual conception of ourselves as humans, but it's really a translucent<br>
veneer over the bulk of what our brains do day in, day out, which comes from our<br>
animal ancestors. Before we ever learn formal or even naturallanguages, our brains<br>
are already highly developed as processors of spatial, tactile, and kinesthetic<br>
information, to name my favorites. This is one reason why the Macintosh has been so<br>
successful as a tool--because it's the first readily available machine to offer at least<br>
at the outer layer a spatially based interface.
</p>
<p>
<b>DKJ:</b> And the reason that's so great is that our brains process spatial information<br>
effortlessly, without our even trying. 
</p>
<p>
<b>MCG:</b> Right, a spatial interface allows us to apply more of our innate biological<br>
intelligence in communicating with the machine.&nbsp;&nbsp;But both structurally and<br>
functionally, the digital computer as a metaphor for the brain is almost completely<br>
inaccurate at every level of analysis. 
</p>
<p>
I think if you look further into the nature of thought and perception, and also look<br>
more carefully through microscopes and macroscopes at what real brain tissue is<br>
doing, you'll see a physical system that exhibits chaotic dynamics in time, has fractal<br>
extent in space, and is inextricably linked to the natural world. Computers are<br>
powerful tools for simulating and visualizing these properties, but they don't<br>
themselves<i>have</i>&nbsp;&nbsp;these properties yet. 
</p>
<p>
<b>DKJ:</b> Especially the links to the natural world. 
</p>
<p>
<b>MCG:</b> Exactly. If you want to apply computational metaphors to the brain, perhaps the<br>
brain is like a fractal architecture computer that can compute infinitely recursive<br>
functions in finite time. 
</p>
<p>
<b>DKJ:</b> Oooh, I like the sound of that. Fractals, computers, infinity, and recursion all at<br>
once.
</p>
<p>
<b>MCG:</b> I like it too, but that's really just a structural metaphor. I'm interested in what<br>
we can learn about how real brains might work, so that we can apply these principles<br>
to next-generation user interfaces and to new non-von Neumann computing<br>
architectures. 
</p>
<p>
In an engineering sense, we're after machine perception. That is, we want future<br>
machines to interact in the human sensory world, rather than forcing humans to<br>
interact in the virtual world of the machine.
</p>
<p>
<b>DKJ:</b> Yeah, to use or program a computer today you still have to interact on the<br>
machine's terms. I think one good approach to changing that is to try to build<br>
computational structures that are like the brain, so that our machines will be a little<br>
more like us. There are 10 billion neurons in the brain, more or less, right? 
</p>
<p>
<b>MCG:</b> More. And perhaps 1015 synapses, which you could say is where a lot of the<br>
computation is going on. 
</p>
<p>
<b>DKJ:</b> OK, more than 10 billion neurons in the brain, and they're wired together<br>
in<i>unbelievably</i> complex ways. The point is this: I'll bet that we can simulate a single<br>
neuron fairly closely with a computer, and over time we can get our simulation closer<br>
and closer to the real thing,<i>arbitrarily</i> close. Further, I'll bet that someday it will be<br>
possible to get 10 billion little computers together and talking to each other. I know<br>
this is a little speculative, but my business card says "Limit Pusher," and I feel<br>
compelled to live up to it. 
</p>
<p>
<b>MCG:</b> Rave on. 
</p>
<p>
<b>DKJ:</b> So we set this thing up--10<i>billion</i> little processing nodes--and we turn it on<br>
and start feeding it information. What will happen? What will it do? I can't help<br>
thinking that whatever it is, it will be something very much like life. And just as<br>
mysterious. 
</p>
<p>
<b>MCG:</b> Well, I don't think it's purely an issue of scale. At Berkeley, we're building a<br>
new ring architecture parallel machine based on superscalar processors that can<br>
accommodate multimodal sensors and effectors. It's called CNS-1 and is spec'd at<br>
upwards of 100 billion operations per second.
</p>
<p>
<b>DKJ:</b> 100 BIPS!&nbsp;&nbsp;</p><p><b>MCG:</b> Right. Or 0.1 TRIPS, which is perhaps a better indication of<br>
how far we have to go. We expect CNS - 1 will be able to simulate many of the<br>
emergent dynamical properties of cell populations observed in real brains--to run<br>
what I call the lava lamp model of the mind. But even this much power won't bring us<br>
"arbitrarily close" to the wetware. I don't think you'll want to say it's alive or that it<br>
works the way a biological brain works. 
</p>
<p>
<b>DKJ:</b> Maybe not, but I think that a network of 10 billion processors could<i>act</i> <br>
something like a brain, could<i> seem</i>&nbsp;&nbsp;like a brain, even though it's not one by any<br>
stretch of the imagination. That idea fascinates me: that a computer, or a bunch of<br>
computers, can behave like something else. This gets back to Turing's thesis that a<br>
computer can simulate anything, if you can describe the thing in enough detail. That<br>
begs the question, though, of whether the simulation is<i>fundamentally</i> the same as the<br>
reality it simulates.
</p>
<p>
<b>MCG</b>: Is it live or is it Memorex? 
</p>
<p>
<b>DKJ:</b> Precisely. It's like comparing painting on the computer to painting using canvas,<br>
brushes, and oils. At one level of description they're identical activities: applying<br>
color to a surface in intricate and skillful ways to produce a little piece of space that<br>
other humans can look at and experience emotion toward. But the tools differ hugely<br>
and, perhaps more important, the experience of using them is completely different. So<br>
I guess what I'm saying is that at the right level of description I believe (well, I<i> want</i> <br>
to believe) that it's possible to "build a brain."
</p>
<p>
<b>MCG:</b> Or to grow a brain. I think you're barking up the wrong dendritic tree.<br>
It's<i>experience</i> that's essential. Brains are dynamic systems that actively reach out into<br>
the sensory world for experience; perception is a creative process, not a passive one.<br>
To talk about building a machine with the capabilities of the human brain you have to<br>
include the same kinds of connections to the world that humans have. In the real tissue,<br>
it goes right down to the level of quantum phenomena and beyond--what I call "real<br>
virtuality."
</p>
<p>
What I've been trying to get across is that real brains operate by virtue of being<br>
physically continuous systems; there's an interplay between the nanoscopic and<br>
macroscopic, the intrinsic and extrinsic, such that structure and function are not<br>
separable. The notion that there exists in brains a "level of description" at which<br>
cognition is implemented as logical operations is a convenient fallacy, what John<br>
Searle calls "closet dualism." It means, for example, that if you want to start<br>
capturing the creative, human aspects of language--not just the literal, but the slang,<br>
humorous, ungrammatical, and allusory--you have to model the dynamics of the<br>
underlying physical processes.
</p>
<p>
<b>DKJ:</b> Hmm, this point about not being able to separate cognition from sensory<br>
experience is important. It's interesting to compare the development of computers<br>
with the development of life.&nbsp;&nbsp;&nbsp;Computer sensors and effectors--the parts of<br>
computers that by necessity touch the world--always seem to lag way behind the other<br>
parts, the computing parts, in their development. And the gap seems to be widening. So<br>
computers are currently wrapped in sensory cellophane, while the connection of<br>
biological systems to the world is very strong and high-bandwidth. 
</p>
<p>
<b>MCG:</b> Exactly. It's likely that in biological systems, sensors and effectors developed<br>
first and, as part of an evolutionary feedback loop, drove the development of the<br>
nervous system.&nbsp;&nbsp;Though now you could say the demands of more sophisticated user<br>
interfaces are driving the development of CPUs.&nbsp;&nbsp;&nbsp;The perceptual side is limited to 2-D<br>
mouse tracking and 1-D clicks and keystrokes. But speech and pen gestures are about<br>
to expand that. Eventually computer-human interface will be polymodal, including<br>
intonation, spatial gestures, eye position, facial expression, and cortical activity<br>
patterns-- what I call the "think-along interface."
</p>
<p>
<b>DKJ:</b> It fascinates me that programmers can so easily get sucked into the machine--I<br>
know<i>I've</i>&nbsp;&nbsp;been there-- despite the very limited modes of interaction with it. 
</p>
<p>
<b>MCG:</b> Yes, in programming, I often feel I'm being sucked into a one-dimensional world<br>
of historical arbitrariness. I think this comes from the fact that while the complexity<br>
of our software systems has increased exponentially, our development tools haven't<br>
kept pace. The current tools fail to providethe real-time, interactive turnaround<br>
that's crucial to maintaining the creative flow. They force us to think too much about<br>
the machine's problems, instead of the human problems we're presumably trying to<br>
solve. 
</p>
<p>
<b>DKJ:</b> Amen. And it's true for nonprogrammers, too. So how would you like to see the<br>
tools improve? 
</p>
<p>
<b>MCG:</b> Well, besides speed--where speed means real-time, no perceptible delay;<br>
anything less is slow-- future tools will have semantic knowledge of the process of<br>
software engineering and eventually of the application you're building. The code<br>
browsers are a good step forward; at least they can automatically determine structure<br>
from syntax. The next step is to automate the build process, the incremental linking of<br>
components, and the maintenance of an audit trail and nonlinear undo space for source<br>
code. Here we start to blur into a dynamic-language sort of model. 
</p>
<p>
<b>DKJ:</b> That's exactly the kind of administrivia that computers are supposed to be good<br>
at. But right now, for most of us, the burden is still on the human. 
</p>
<p>
<b>MCG:</b> It sure is. Where we want to head is to shift the focus of the iterative process<br>
from the syntax level--compilation, debugging--which is what the machine is<br>
concerned with, to the level of design and validation, which is hopefully where the<br>
programmer is trying to solve the semantic problems of the application. 
</p>
<p>
<b>DKJ:</b> Way back in the 1940s Turing talked about the fact that ". . . as soon as any<br>
technique becomes at all stereotyped it becomes possible to devise a system of<br>
instruction tables which will enable the electronic computer to do it for itself." In<br>
other words, as soon as we can describe how we do a job, we can program the machine<br>
to do it for us. This is happening, but slowly. As an amusing footnote, he went on to say<br>
"It may happen however that the masters [programmers] will refuse to do this. They<br>
may be unwilling to let their jobs be stolen from them in this way. In that case they<br>
would surround the whole of their work with mystery and make excuses, couched in<br>
well chosen gibberish . . ." He was a pretty prescient guy. 
</p>
<p>
[Setting his napkin on the table] Well, I guess we should try to wrap it up here; our<br>
readers' MacApp builds are probably finished by now, and we'll be losing them soon.<br>
Let's try to wring a message out of our ramblings, something developers can take home<br>
with them. How about this: Strive to bring computers ever more firmly into the world<br>
of people, rather than trying to cram people ever more firmly into the world of<br>
computers. The differences can be subtle, but the distinction is very important. 
</p>
<p>
<b>MCG:</b> Well, I think we can and will go much further toward humanizing the experience<br>
of using computers. But I don't think we have to couch what we do in gibberish to keep<br>
our jobs, because programming is fundamentally a creative discipline. Like other<br>
creative disciplines, when you've done it long enough and intently enough, you tend to<br>
see its way reflected in everything you perceive. You could say programming is a way<br>
of seeing. That leads us to computers as tools for extending human visualization.
</p>
<p>
[Flipping up his shades] The point is that it's human vision--not the<br>
technology--that's crucial.&nbsp;&nbsp;&nbsp;When we create tools and toys and lifestyles that separate<br>
and insulate us from nature, we further the consumption and destruction we see all<br>
around us. But I think we can see past the empty goal of creating trillion dollar<br>
markets for our products. As humans, we've always had the infinite power to change<br>
our minds. It's time we tap that power by creating tools that connect us--to each<br>
other, to the earth--and enable us to meet the real life-or-death challenges we face on<br>
this planet. As programmers and technologists we're in a key position to determine the<br>
future by the choices we make every day. I hope each of us can make every keystroke<br>
and every mouse click a step toward a sustainable society. 
</p>
<p class="spacer">&nbsp;</p>
<p>
<b>RECOMMENDED READING</b>
</p>
<ul>
<li><i>Alan Turing: The Enigma</i>  by Andrew Hodges (Simon &amp; Schuster, 1983).</li>
<li><i>The Three-Pound Universe</i>  by Judith Hooper and Dick Teresi (Tarcher<br>
Press, 1986).</li>
<li><i>Who Needs Donuts?</i>  by Mark Alan Stamaty (The Dial Press, 1973).</li>
</ul>
<p>
<b>DAVE JOHNSON</b> once borrowed a friend's video camera so that he could spy on his<br>
dogs when they were alone. He carefully--and gleefully--set up the camera near the<br>
front door, turned it on, and went out for dinner and a movie. The dogs mostly just<br>
slept, with an occasional barking fit, apparently just for doggie grins. It was really<br>
very dull viewing except for one incident about halfway through: the smallest dog,<br>
affectionately known as Dinky, sat down right in front of the camera, stared balefully<br>
into the lens for a moment, then put her head back and howled for a full five minutes,<br>
something Dave has never seen before or since. *
</p>
<p>
<b>MICHAEL GREENSPON</b> is a doctoral student in the department of Electrical<br>
Engineering and Computer Science at UC Berkeley. When he's not cramming for quals,<br>
he can often be overheard trying to explain the cost benefits of telecommuting to Apple<br>
managers. (We're still not sure when he sleeps.) If the sun's out, you're sure to find<br>
him soaking up some of it; since the release of the Macintosh PowerBook and<br>
ToolServer, he's hardly been seen indoors except for an occasional rave. In fact, he and<br>
Dave Johnson were recently spotted rigging a LAN in the outfield at Golden Gate Park.<br>
He does, however, respond to his e-mail: he can be reached via AppleLink as INTEGRAL<br>
or on the Internet as mcg@icsi.berkeley.edu.*
</p>
<p>
<b>Dave welcomes feedback</b> on his musings. He can be reached at JOHNSON.DK on<br>
AppleLink, dkj@apple.com on the Internet, or 75300,715 on CompuServe.*
</p>
</body>
</html>
