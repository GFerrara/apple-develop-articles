<!DOCTYPE html>
<html>
<head>
<!-- Article ID: 35 - Extracted from develop-1992 -->
<!-- on 2024-01-22 by Giorgio Ferrara - giorgio<dot>ferrara<at>gmail<dot>com -->
<!-- The content is protected by the copyright of its respective owners -->
<title>August 92 - THE NETWORK PROJECT: DISTRIBUTED COMPUTING ON THE MACINTOSH</title>
<link href="../common/styles/main.css" rel="stylesheet" type="text/css">
</head>
<body>
<h2>THE NETWORK PROJECT: DISTRIBUTED COMPUTING ON THE<br>
MACINTOSH</h2>
<h1>G&#220;NTHER SAWITZKI</h1>
<p>
<img src="img/218.gif" width="180 px"></img>
</p>
<p>
<i>&nbsp;Distributed computing is the wave of the future, soon to come rolling onto the shores</i><br>
<i>of programming. Programmers should be prepared for the possibilities and challenges</i><br>
<i>that distributed computing will offer. The NetWork model proposes a design strategy</i><br>
<i>and provides a testbed implementation that enables you to explore and experiment with</i><br>
<i>distributed computing on the Macintosh. While this article may not help you write a</i><br>
<i>better application today, it will help familiarize you with the idea of distributed</i><br>
<i>computing so that when system support for it comes along, you'll be ready to take</i><br>
<i>advantage of it.</i>
</p>
<p class="spacer">&nbsp;</p>
<p>
&nbsp;As computing evolves, we're rapidly moving from a reliance on discrete personal<br>
computers and workstations to a new type of computing infrastructure--a<i>computing</i><br>
<i>environment.&nbsp;&nbsp;</i> In a computing environment, applications will make massive use of<br>
many partially coordinated or uncoordinated autonomous computing devices. That is,<br>
one device won't necessarily know which application subtask any other device is<br>
working on or when and how any other device is completing its particular subtask.&nbsp;&nbsp;<br>
These autonomous devices will be connected by multiple threads of communication.<br>
What's more, the computing environment of tomorrow will be continually changing,<br>
with portable devices moving in and out and with new capabilities added dynamically.<br>
Devices will change in time and will have varying availability. In short, distributed<br>
computing in an environment with no guaranteed stability will become the order of the<br>
day. 
</p>
<p>
&nbsp;Visions like Apple's Personal Digital Assistant and the TRON Project give some idea of<br>
what we'll see. The Personal Digital Assistant will be a small intelligent device that<br>
will help you with some aspect of living and working; for example, it might be a smart<br>
map leading you around in a town you're visiting, or a dietary assistant helping you<br>
plan a week's meals, or a TV viewer helping you trace back a thread of interesting<br>
news you've just become aware of. TRON will work the other way, making your<br>
environment smart on its own; for example, the washing machine itself will place<br>
orders for more detergent and will tell the warm water supply to diminish for a<br>
moment because there will be hot wastewater that will feed a heat exchanger. Both<br>
these visions will soon become reality in a distributed computing environment.&nbsp;&nbsp;What<br>
distributed computing will mean for users is that they'll have access to the<br>
considerable computing power that's typically left unused in today's computing setup.<br>
Implementing a system for distributed computing is easy if you reduce or restrict the<br>
availability of personal workstations to their users. The challenge addressed by the<br>
NetWork Project is to make access to idle workstations possible while still<br>
guarantee-ing users immediate access to their personal workstations. NetWork is a<br>
minimal communication and management model designed to operate in this<br>
environment. By handling communication and managing computing resources, it frees<br>
the programmer to think about how to split up a task so that it can be done by multiple<br>
workstations working on small pieces in an uncoordinated and asynchronous way.
</p>
<p>
NetWork is available on the current<i>Developer CD Series</i> disc and via Internet for those<br>
who want to try it out. This article describes the NetWork Project itself, considers the<br>
types of applications that are most amenable to a distributed computing approach,<br>
thoroughly examines the NetWork model, and then suggests how to implement a<br>
NetWork program on the Macintosh. Because I'm a statistician I've included some<br>
discussion of statistical underpinnings. I've presented this discussion separately,<br>
though, so that if you don't find mathematics fascinating, you can skip it. 
</p>
<h2>HISTORY OF THE NETWORK PROJECT</h2>
<p>
NetWork is a project of StatLab, the statistical laboratory at the University of<br>
Heidelberg. StatLab was founded in 1984 to complement the existing mathematical<br>
statistics research group by studying practical applications of advanced statistical<br>
methods. We took a look at what was available as the hardware base for our work and<br>
chose the Macintosh, but since no Macintosh was on the German market at that time,<br>
we bought a Lisa. We've been developing our statistical software on Lisa and Macintosh<br>
ever since. This eventually brought us into contact with Larry Taylor, representing<br>
Apple's Advanced Technology Group in Europe. 
</p>
<p>
During a November 1988 meeting, we discussed future perspectives in computing<br>
with Larry. We tried to identify current gaps and obvious next steps. One thing we<br>
could point to was the discrepancy between the amount of computing power we had<br>
installed and the return it gave us. At that time, we were running an installation of<br>
Macintosh Plus and Macintosh II computers, and the usual turnaround time for a<br>
statistical simulation was one night. This was better than the turnaround time for the<br>
same job on the IBM mainframe time-sharing system (about a week), but still it was<br>
frustrating to have to wait so long while other computer resources lay idle. Just the<br>
same, given the Macintosh's character as an absolutely devoted servant of one master,<br>
how in the world could we find a way to share its computing power while still<br>
guaranteeing reliable and efficient service for the Macintosh owner? 
</p>
<p>
In December 1988 we had a visit from Bill Eddy, then head of the statistics<br>
department at Carnegie Mellon University. In a lecture he mentioned that the CMU<br>
people were annoyed at the discrepancy between installed computing power and the<br>
return it gave them and were doing research on executing iterations asynchronously<br>
(in an uncontrolled way) to make use of aggregated computing power. Until then, I'd<br>
been thinking of the solution only in terms of distributed computing in a<i>controlled</i><br>
environment. Bill emphasized that in the computing environment of the future,<br>
computing time per se won't be expensive. In fact, in a network consisting of thousands<br>
of CPUs, computing power will be<i>free</i> --if you can access it. This started me thinking<br>
about how we could possibly make a distributed system work under these<br>
circumstances--that is, in a large heterogeneous environment. 
</p>
<p>
When we next met with Larry Taylor in February 1989, I claimed that we could build<br>
a system for distributed computing based on the Macintosh philosophy of the absolute<br>
priority of the user and at the same time able to cope with a large environment. Larry<br>
agreed to support the project, and we formed a team consisting initially of Larry, me,<br>
Reimer K&#220;hn and Leo van Hemmen of the Heidelberg Neural Network Research Group,<br>
and Joachim Lindenberg, then a computer science student at Karlsruhe University. 
</p>
<p>
The project started in May 1989. We called it the NetWork Project, a reference to the<br>
fact that in the future the only measure of performance that will matter will be the<i>net</i><br>
<i>work done per unit of time</i> , not cumulative computing time or other measures of<br>
resource utilization. We gave ourselves six months to decide on the specifications and<br>
build a working prototype of a distributed system that would fit a Macintosh<br>
environment and be scalable up to some thousands of CPUs. AlthoughMacintosh was the<br>
original development target, we did make sure that the system would run in any other<br>
decent environment (DEC TM, UNIX&#174;, what have you). We finished our first release<br>
one week late in November 1989. As they say, the rest is history. 
</p>
<p>
Worth mentioning is the fact that with NetWork's accelerated development schedule,<br>
we didn't spend a lot of time on planning and administration. That's the nature of<br>
progress sometimes.&nbsp;&nbsp;&nbsp;Fortunately, Apple's Advanced Technology External Research<br>
Group had resources available to allocate to the project on the spot. Without this kind<br>
of flexible support, the NetWork Project could not have succeeded.
</p>
<h2>CANDIDATES FOR DISTRIBUTED COMPUTING</h2>
<p>
Distributed computing will be a great boon to applications where computing power is<br>
critical and where the computing task can be split into discrete subtasks. Such<br>
applications include the following:
</p>
<ul>
<li>compiling a new product using a superoptimizing compiler</li>
<li>solving an optimization problem like placing chips on a board</li>
<li>generating computer graphics, especially ray tracing</li>
<li>performing optical character recognition</li>
</ul>
<p>
In these cases, processing may take too long on one particular machine, but if the<br>
application can tap into the computing power available by sending out subtasks, the<br>
processing can be completed in a much more timely manner. 
</p>
<p>
Many applications that involve working on large data sets can benefit from additional<br>
computing power, even in an environment where completion of a subtask is not<br>
guaranteed. Such tasks include sorting with some appropriate merge/sort algorithm:<br>
the global sort can benefit if a subset has already been sorted by another machine but<br>
need not be affected if the result of the presorting is not available. The same applies to<br>
searching and practically all major accounting tasks. Any statistical analysis based on<br>
exponential families, like normal (Gaussian) distributions, can also benefit from<br>
distributed computing: in these analyses you can calculate global sufficient statistics<br>
from those of partial data sets, if available. Problems of this type are completely<br>
splittable into subtasks and clearly are fine candidates for distributed computing. 
</p>
<p>
But what about problems that have a stronger internal structure than those that are<br>
completely splittable? What about iterative and recursive problems, or problems that<br>
lead to pipeline processing or networks of data flow? We can't automatically assume<br>
that these can take advantage of additional computing power in a distributed<br>
environment where the completion of a subtask isn't guaranteed.&nbsp;&nbsp;&nbsp;Still, mathematical<br>
theory can help us identify problems of this type that are good candidates for<br>
distributed computing.
</p>
<p>
<b>A SPECIAL CLASS: ASYNCHRONOUS ITERATIONS</b>As an example of problems with<br>
a stronger internal structure than those that are completely splittable, we'll focus on<br>
iterative algorithms. The trouble with running an iterative algorithm in a<br>
nonguaranteed distributed environment is this: the outcome of iterations in one part of<br>
the problem might critically depend on results from iterations in other parts, and the<br>
result of a previous iteration may or may not be available for the next round. Even if<br>
the original iteration converges to a correct result, we don't know whether the same<br>
will hold true if the iterations are done asynchronously.
</p>
<p>
Suppose, for instance, we have a mapping to be iterated that operates on some<br>
high-dimensional vector or matrix. To prepare for a distributed version, we restrict<br>
the mapping to a subset by providing the full input but allowing the mapping to operate<br>
only on the coordinates selected by the subset. We allocate different subsets to<br>
different machines for a number of iterations. These iterations are performed in<br>
parallel. The results are collected as they come in and new tasks based on these results<br>
are redistributed repeatedly.
</p>
<p>
In a guaranteed environment, we could wait for all results to come in before assigning<br>
the next round of tasks. But in a nonguaranteed environment, we don't know whether a<br>
result will come in, and if it does, when. Synchronizing tasks may be impossible. And<br>
even when possible, it would be a waste of computing power, because we would spend<br>
much of our time waiting for the latest result to come in.&nbsp;&nbsp;&nbsp;Enter asynchronous<br>
iterations. Asynchronous iterations don't spend time on waiting. New tasks are assigned<br>
as partial results come in. The only question is, will asynchronous iterations give us a<br>
correct result? 
</p>
<p>
&nbsp;Mathematical theory can tell us under what conditions asynchronous iterations will<br>
yield correct results in a nonguaranteed distributed environment. According to G. M.<br>
Baudet in his paper "Asynchronous Iterative Methods for Multiprocessors" in<br>
the<i>Journal of the ACM</i> , if the original mapping is what mathematicians call a<br>
Lipschitz contraction, in general an asynchronous iteration will converge to the same<br>
limit as the original mapping. Many numerical methods can be formulated such that<br>
they fall into this class. For example, the time-consuming core in many<br>
applications--like solvers for differential equations, optimizers, or matrix<br>
inversions--can be implemented as algorithms that correspond to Lipschitz<br>
contractions. 
</p>
<p>
<b>&nbsp;AN EXAMPLE: NEURAL NETS</b><br>
As an example of the use of asynchronous iterations in a distributed computing<br>
environment, let's look at a neural net applied to picture reconstruction, from work<br>
done jointly by Reimer K&#220;hn and me. The specific variant of neural nets we're using is<br>
a Hopfield net. Neural nets provide a useful model for cognitive functions; when we<br>
reconstruct a picture using a neural net, we're modeling how humans might recognize<br>
someone they know in a blurred photograph. 
</p>
<p>
&nbsp;K&#220;hn and I developed an interactive program for associative recall of visual patterns<br>
called Spinning Brain. The program, which is included on the<i>Developer CD Series</i> disc,<br>
first trains a neural net on a series of pictures. Each pixel in a picture is linked to a<br>
neuron in our net. Then rudimentary pictures based on the originals are presented to<br>
the net. The program then reconstructs the originals from the rudimentary pictures<br>
by iterating a certain transformation until a stable state is reached.
</p>
<p>
&nbsp;In a distributed computing environment, we can take a slice, represented by a subset<br>
of the pixels, and ask an idle workstation to perform a number of transformations on<br>
it. The restriction to one slice means that only pixels in that slice can be changed,<br>
although the full picture is available as initial information. As illustrated in Figure 1,<br>
while one slice is being processed on one workstation, we pass other slices as subtasks<br>
to other workstations. When we get a result, we merge the processed slice with the<br>
rest of the picture; that is, our updating function uses the processed slice to replace<br>
the corresponding part of our original picture. This may introduce an error because<br>
the processed slice may depend on the state in other slices, which may have changed<br>
significantly in the meantime. We repeat the assignment of tasks until we reach a<br>
stable state. This example isn't a Lipschitz contraction and thus isn't covered by<br>
Baudet's convergence result, but under mild regularity conditions, convergence to the<br>
original limit still holds.
</p>
<p>
<img src="img/219.gif" width="600 px"></img>
</p>
<p>
<b>Figure 1</b>Spinning Brain in Action
</p>
<p>
Neural nets are an interesting target for asynchronous distributed computing. If we<br>
accept that neural nets provide a useful model for cognitive functions, we still must<br>
admit that in real biological systems there's no indication of global synchronization<br>
except on a very large scale (for example, daily rhythm). Information processing<br>
takes place in a distributed asynchronous environment (the brain).&nbsp;&nbsp;&nbsp;And we must<br>
admit that this isn't a guaranteed environment: some results may be late or may never<br>
be reached. This is true for the individual and even more so for collective or social<br>
cognitive phenomena. So experiences with neural nets in our environment might shed<br>
light on critical aspects of neural network modeling in an asynchronous,<br>
nonguaranteed environment. 
</p>
<h2>THE NETWORK MODEL OF DISTRIBUTED COMPUTING</h2>
<p>
Now that you know how the NetWork model was developed and have an idea of the kinds<br>
of applications that might take advantage of a distributed computing environment, we<br>
turn to the model itself. First I'll list the design goals for the NetWork model; then I'll<br>
list the services NetWork needs and the services the Macintosh makes available. From<br>
there I'll explain the principles of operation and the layers of the NetWork model.<br>
Finally, I'll discuss some important strategies incorporated in the NetWork model to<br>
help meet its goals. 
</p>
<p>
<b>DESIGN GOALS</b>Simply stated, the primary goal of the NetWork model is to make use<br>
of the idle resources of a network while respecting the absolute priority of events and<br>
processes initiated by each machine's owner. The model implementation runs in an<br>
unobtrusive way, making use of free network resources but interfering as little as<br>
possible with any user request. The approach we take is to allow other users to borrow<br>
the computing power if a machine is idle, but to impose a strict rule: if the owner<br>
accesses the machine, the guest is given only minimal time to retreat. The machine has<br>
to be completely available without any noticeable delay. This imposes a time to leave of<br>
about 1/10th of a second, which might be too short for any proper notification or<br>
cleanup. 
</p>
<p>
NetWork takes the view that for every machine there is an owner. The owner may, but<br>
need not, correspond to a real user. For example, if the machine is a dedicated server,<br>
the server process can be considered the owner. Furthermore, a NetWork machine in<br>
general will, but need not, correspond to a physical machine. For example, a cluster of<br>
CPUs may be considered a machine for the purposes of NetWork. 
</p>
<p>
Even if there is no immediate owner access, a machine may be busy because an<br>
owner-initiated process needs the resources of the machine. The absolute priority of<br>
the owner must extend to owner-initiated processes as well. A machine is considered<br>
idle, or free for the purposes of NetWork, if there is no owner access and no<br>
owner-initiated activity. NetWork is only allowed to use resources that are free in<br>
this sense. 
</p>
<p>
The goal to use only free network resources also affects communication. The effect for<br>
any owner other than the one requesting network services should be barely noticeable,<br>
and care must be taken not to compete for network bandwidth. Unfortunately, with<br>
current technology it's nearly impossible to avoid interfering with other users. All<br>
that can reasonably be done is to use "second-class" communication where possible and<br>
to take measures to minimize the number of network accesses and the additional<br>
network load. 
</p>
<p>
To allow for open environments, independence of the underlying communication model<br>
(including network/file/bus-based communication, network topology, and such) and<br>
adaptability to heterogeneous hardware are additional design goals of NetWork. We<br>
aren't narrow-minded: we don't mind making use of a Cray computer via Hyperchannel<br>
if it's idle. Finally, to invite experiments with our model, the implementation of an<br>
asynchronous iteration scheme should be as near to that of a standard iteration scheme<br>
as possible.
</p>
<p>
In summary, then, the design goals of the NetWork model are as follows:
</p>
<ul>
<li>immediate availability of any machine to its owner</li>
<li>minimal interference with owner communication</li>
<li>independence of communication model</li>
<li>adaptability to heterogeneous hardware</li>
<li>close resemblance to a standard iteration scheme</li>
</ul>
<p>
<b>NECESSARY SERVICES</b>To meet the design goals, NetWork needs the following<br>
services:
</p>
<ul>
<li>idle/busy state monitoring to keep track of owner activity</li>
<li>process management to launch a process to serve a remote request and to<br>
kill all processes launched by NetWork when the owner accesses the machine</li>
<li>communication to pass message descriptions and results</li>
</ul>
<p>
First, NetWork needs a monitor whose only task is to keep track of whether the<br>
machine is idle or whether it's active on behalf of its owner. Since this is<br>
machine-specific information, each machine must be equipped with such a monitor,<br>
which we call an idle monitor. 
</p>
<p>
Second, NetWork needs a process manager that's capable of handling all process<br>
management on remote request. If the machine is idle, the process manager can launch<br>
processes to fulfill remote computing requests, and it's responsible for cleaning up all<br>
remote processes immediately if the state of the machine changes from idle to<br>
busy--that is, if the owner accesses the machine. The process manager is informed of<br>
any idle/busy transition by the idle monitor. It's responsible for guarding the priority<br>
of the owner. The process manager keeps track of active processes on the local<br>
machine.
</p>
<p>
Third, NetWork needs a communication system. The communication system has to<br>
guarantee reliable services in a possibly unreliable environment. Moreover, it should<br>
take special precautions to minimize interference with owner communication, as<br>
required by the NetWork design goals.
</p>
<p>
The idle monitor, the process manager, and the communication system form the core of<br>
the NetWork model. They must be present in any implementation of NetWork. This<br>
core provides convenient primitives for distributed computing while shielding the<br>
transport system. In this respect it resembles other approaches, such as those<br>
described by G. Bernard, A. Duda, Y. Haddad, and G.&nbsp;&nbsp;&nbsp;Harrus in their article<br>
"Primitives for Distributed Computing in a Heterogeneous Local Area Network<br>
Environment" and by T. J. Gardner, I. M. Gerard, C. R. Mowers, E. Nemeth, and R. B.<br>
Schnabel in their paper "DPUP: A Distributed Processing Utilities Package." Going<br>
beyond these approaches, NetWork tries to provide a minimal model suited even for a<br>
nonguaranteed environment. 
</p>
<p>
<b>SERVICES AVAILABLE ON THE MACINTOSH</b><br>
Given that an idle monitor, a process manager, and a communication system are<br>
necessary to the NetWork model, let's look at what we've got on the Macintosh.
</p>
<p>
The Macintosh doesn't have an idle monitor. If one were available, many applications<br>
could take advantage of it. It could relieve applications of the tedious calculations<br>
needed to find out which sleep value to use. (Some applications never seem to get this<br>
right!) And it would allow a clean strategy for background tasks like indexing and<br>
compressing. So we decided that we should implement an idle monitor for NetWork. 
</p>
<p>
Fortunately, the Macintosh Operating System provides an event queue. Since the OS is<br>
user oriented, there's a clear model for user events, and all are funneled through the<br>
event queue. But looking at the event queue isn't sufficient. A user might have started a<br>
time-consuming calculation and left for lunch. In this case, the machine should be<br>
considered busy. If it's not, the user might come back and find the machine in slow<br>
mode or serving someone else. On the Macintosh, we run a statistic of the CPU program<br>
counter to catch these situations. This still leaves frontmost applications that are<br>
allowed to consume arbitrary time on the Macintosh. This is where the most important<br>
feature of the Macintosh enters: the Human Interface Guidelines. We monitor any<br>
cursor changes and busy cursor states to catch this situation as well.&nbsp;&nbsp;&nbsp;A process<br>
manager is available with System 7. This takes care of many tasks that NetWork has to<br>
fulfill under previous system software. However, processes under System 7 don't have<br>
priority attributes: System 7 can launch processes but doesn't know which processes<br>
to kill when the owner comes back. NetWork has to implement this needed<br>
functionality. What's more, the System 7 Process Manager is designed to launch an<br>
application on a single machine and isn't set up to handle remote launching, so this<br>
additional functionality has to be provided by NetWork. To enable portability, NetWork<br>
has its own process manager. If you're using System 7, the NetWork process manager<br>
maps to the System 7 Process Manager where appropriate and has augmented<br>
functionality where necessary. 
</p>
<p>
AppleTalk is the native communication system on the Macintosh. There are<br>
restrictions, however.&nbsp;&nbsp;&nbsp;Current implementations of AppleTalk support just one<br>
transport system. NetWork has its own communication system, which maps to<br>
AppleTalk if appropriate but isn't restricted to AppleTalk.&nbsp;&nbsp;&nbsp;With NetWork's<br>
communication system you can talk UDP from the TCP/IP suite to one machine while<br>
engaging in AppleTalk with another one. NetWork supports any number of concurrent<br>
transport systems, with no gateway needed. And the NetWork communication system<br>
tries to reduce additional communication load that would compete with immediate<br>
users.
</p>
<p>
NetWork's communication system is message based. We wanted our message-passing<br>
system to be as flexible and powerful as possible. In particular, we wanted it to have<br>
extremely low overhead, we didn't want it to impose unnecessary size limitations, and<br>
we didn't want it to be restricted to certain operating systems or transport systems.<br>
For these reasons, we decided to use our own message- passing system, instead of using<br>
Apple events. 
</p>
<p>
For the Macintosh, we've bundled the idle monitor, the process manager, and the<br>
communication system kernel into a control panel extension, the NetWork Processor.<br>
To use NetWork, you move the NetWork Processor into your System Folder and restart<br>
your Macintosh. Programmers can access the NetWork services with the help of a<br>
library (NetWorkLib.o) and interface files that come with NetWork. For tips on how<br>
to use NetWork's idle monitor and communication system, see "Cheap Thrills: Using<br>
NetWork's Services."
</p>
<p>
<b>NETWORK LAYERS AND PRINCIPLES OF OPERATION</b><br>
NetWork views the computing environment as a set of machines with processes<br>
running on them.&nbsp;&nbsp;&nbsp;Each machine has an owner, who has absolute priority on this<br>
machine. Processes can run on behalf of the (local) owner, or they can satisfy a<br>
remote request. If a process is running on behalf of a remote request, it should be<br>
terminated immediately when the owner accesses the machine. A process handles tasks<br>
and eventually may generate tasks for remote execution. A task can be delegated to<br>
another process, possibly on a different machine, and results may or may not be<br>
returned. 
</p>
<p>
The NetWork programming model has three layers, as shown in Figure 2. The top<br>
layer, the application layer, contains the application-specific code. Apart from<br>
initialization and cleanup sections, this code should be able to define subtasks and to<br>
handle results from subtasks if available.&nbsp;&nbsp;&nbsp;The specific details of this layer are, of<br>
course, application dependent.
</p>
<p>
<img src="img/220.gif" width="141 px"></img>
</p>
<p>
<b>&nbsp;Figure 2</b> Layers of the NetWork Programming Model
</p>
<p>
The scheduler layer provides support for asynchronous iterations. The NetWork<br>
scheduler monitors and stimulates the generation, assignment, and integration of<br>
subtasks. While the proper generation of subtasks is application dependent,<br>
theNetWork scheduler can monitor the overall system behavior and try for dynamic<br>
load balancing. Task assignment is an interaction between scheduler and application.<br>
The communications layer forms the basis of the NetWork design. It provides the basic<br>
communication services needed for the network system. In particular, it provides<br>
transport shielding to cope with a potentially unreliable environment. If necessary<br>
(for example, to implement diagnostic or management tools), the services of the<br>
communication system can be accessed directly, avoiding the scheduler. 
</p>
<p>
NetWork is implemented as a message-passing system. A process may send task<br>
descriptions as messages, and results are returned as messages. If a process is set up<br>
for task generation, the scheduler will ask the application periodically for the<br>
definition of a new task. If a new task definition is given, the scheduler will pass this<br>
information to the communication system for further transmission. If a process is set<br>
up for result handling, the scheduler will inform the application of any result<br>
received by the communication system.
</p>
<p>
In the NetWork model, messages flow as diagrammed in Figure 3. The task-generating<br>
application defines a task message and hands it to the scheduler. The scheduler does the<br>
necessary housekeeping and passes the message to the NetWork Processor, which<br>
communicates it to the receiving NetWork Processor. The receiving NetWork<br>
Processor launches the destination application (if necessary). The destination<br>
scheduler passes the message to the task handler of its application. 
</p>
<p>
<img src="img/221.gif" width="419 px"></img>
</p>
<p>
<b>&nbsp;Figure 3</b> Simplified Diagram of the NetWork Message Flow
</p>
<p>
Since NetWork is designed to work in a nonguaranteed environment, no assumptions<br>
about the lifetime of a communication partner are made. Hence, a process that's<br>
generating tasks doesn't know its target in delegating a task. The scheduler proposes a<br>
target to which the next task can be delegated when asking for a new task definition.<br>
The application is free to accept this proposal or to select a different target using a<br>
lookup server or any other source of information. 
</p>
<p>
Messages are addressed to processes, residing on machines. However, in a<br>
nonguaranteed environment, no assumption about the existence of a communication<br>
partner can be made. The address refers to a process class (defined as any instantiation<br>
of the underlying program) rather than to a particular process instance. On the<br>
recipient machine, NetWork checks whether the target is active--that is, whether<br>
there is a corresponding process. If so, the message is made available. If the machine is<br>
idle but no corresponding process is active, NetWork tries to locate the program and<br>
launch it first. If it fails, the message is discarded. No prolonged negotiation takes<br>
place and no acknowledgment is made. The task message is an implicit launch command,<br>
and the completed result is the only acknowledgment, if any. If the state of a machine<br>
changes from idle to used--that is, if the owner accesses the machine--NetWork<br>
immediately kills any application it has launched. 
</p>
<p>
<b>SOME IMPORTANT STRATEGIES</b>The NetWork model uses three important<br>
strategies to meet its goals effectively. These strategies have to do with minimizing the<br>
communication load, recruiting idle machines that are most likely to remain idle, and<br>
minimizing the probability of conflicts among incoming messages. 
</p>
<p>
<b>Strategy 1: Minimize the communication load. </b>As stated earlier, one of<br>
NetWork's design goals is to minimize the communication load to avoid competing with<br>
machine owners. We've already mentioned that NetWork allows a process to be<br>
launched implicitly by sending a task addressed to it, and that NetWork avoids<br>
negotiations and explicit launch sequences. This is done to reduce additional<br>
communication load. Of course, it's possible to use explicit authentication and<br>
authorization schemes and exert direct control over launching with NetWork, and in<br>
any environment where security is required this will be necessary. But it's in no way<br>
required for a minimal implementation of distributed computing, so it's not required<br>
in the NetWork model. 
</p>
<p>
The decision not to enforce any session maintenance techniques, nor even any<br>
acknowledgment schemes, is another measure to minimize communication load.<br>
NetWork can operate in a connectionless mode, so session maintenance techniques or<br>
acknowledgment schemes aren't required. Again, if needed, both can be applied. 
</p>
<p>
Since NetWork is designed to work in a noisy environment where no guarantees of<br>
availability or performance are given, NetWork has to be prepared for messages that<br>
are outdated or out of context.&nbsp;&nbsp;&nbsp;To minimize communication load in these cases,<br>
NetWork encourages a separation of descriptive information from bulk load.<br>
Conceptually, each NetWork message consists of a priority part, which should be small<br>
and contain just enough information to indicate whether the message is usable in a<br>
given context, and the message core, which should contain the bulk of information, as<br>
shown in Figure 4. When a message arrives, the priority part along with the usual<br>
administrative information is presented to the recipient for inspection. Only if the<br>
recipient accepts the message as usable does the core information need to be<br>
transported.
</p>
<p>
<img src="img/222.gif" width="525 px"></img>
</p>
<p>
<b>&nbsp;Figure 4</b> Message Segments
</p>
<p class="spacer">&nbsp;</p>
<p>
The separation of priority information from core information is only a conceptual one.<br>
The NetWork communication manager will do packing/unpacking and transport in a<br>
way that seems optimal for the transport system. In particular, for a packet-oriented<br>
transport system, the communication manager will pack header and priority<br>
information into a first transport system package and fill it up with as much core<br>
information as fits reasonably into this package. (Note that the communication<br>
manager should signal a received message only if all parts of the priority data are<br>
received, but it need not rely on a handshake.) Subsequent packages with the<br>
remainder of the core information will be sent only if the recipient requires this<br>
information. Thus, unnecessary information load can be avoided. The scheduler<br>
included in the NetWork distribution package is adapted to this optimization strategy. 
</p>
<p>
<b>Strategy 2: Recruit the idle machines most likely to remain idle. </b> We<br>
need to identify idle machines and have a strategy to allocate them for cooperation. The<br>
idle state is determined by the idle monitor, and idle machines can be registered as<br>
possible compute servers using a lookup server. Of course, we'd prefer to use those<br>
machines that will be available for some time and to avoid those machines that are free<br>
for the moment but will be used shortly. To do this, we need some way to distinguish<br>
the most promising machines--some method to ascertain what we'll call<br>
the<i>hazard-to-leave-idle-state</i> . Our first informal review of literature and<br>
interviews with experts gave us little hope of finding some indicator of this hazard.<br>
Still, disregarding any recommendations, we implemented an allocation scheme based<br>
on observed idle times and then measured the availability of idle machines. Our results<br>
implied that the frequency of useless (short-time) allocation of machines can be<br>
drastically reduced by waiting until a certain critical idle time has been exceeded<br>
before allocating a task to a particular machine. This is the approach we take in the<br>
NetWork implementation. (If you're interested in the details of how we arrived at our<br>
conclusion, see "Diagnostic Plots for the Statistically Minded.")
</p>
<p>
<b>Strategy 3: Filter incoming messages. </b>A scheduler for NetWork can be<br>
integrated in applications and make use of the services of the NetWork system. In the<br>
current NetWork implementation, a scheduler prototype is provided, together with a<br>
library that interfaces with the NetWork communication system. The scheduler asks<br>
the application regularly whether a new task should be defined or informs the<br>
application of incoming messages. It also does a preliminary check for the usefulness<br>
of incoming messages, filtering out messages that can be identified as useless or<br>
outdated with respect to the application context. 
</p>
<p>
To guarantee fail-safe behavior, tasks should be allocated redundantly. As a<br>
consequence, more than one result may be returned relating to a particular subtask.<br>
This poses a problem to the scheduler.&nbsp;&nbsp;&nbsp;Assume we have two incoming partial results.<br>
If the first result is based on an earlier state and if less work (fewer iterations) has<br>
been done for this result, it's clearly outdated. Or if the first result is based on more<br>
recent information and if more work has been invested in this result, it's clearly the<br>
better one and should replace the other result. The remaining cases enter a critical<br>
region where the scheduler is required to make a decision. (See "Deciding Between<br>
Results" if you'd like to read this in mathematical language.)
</p>
<p>
Our strategy is to accept only those packages that can be accepted without any further<br>
analysis.&nbsp;&nbsp;&nbsp;Instead of putting computational power into evaluating the optimal<br>
acceptance decision, we try to keep the probability of entering the critical region low.<br>
Since our criterion is the time it takes to perform the task, and both acceptance<br>
decision making and task allocation are done by the same machine, there's a trade-off<br>
between those two, and we can keep the expected loss due to a wrong decision small by<br>
keeping the probability of conflicts low. 
</p>
<p>
The NetWork scheduler uses an adaptive task assignment scheme to minimize the<br>
probability of these conflicts: from the received results, the scheduler tries to<br>
estimate the relative complexity of a subtask and the relative computing power of the<br>
partners. New tasks are calibrated so that the expected return time is distributed<br>
homogenously, thus reducing the probability of conflicts. An application can override<br>
or augment the generic strategy as provided by the scheduler with a more<br>
application-specific strategy. In the Spinning Brain example that comes with<br>
NetWork, you can see the scheduler trying to adapt to the relative computing power<br>
and reliability of the partners. Choose the Scheduler menu item from the Control<br>
menu. You'll see a running plot of the task size assigned to machines versus the time of<br>
allocation by NetWork, as illustrated in Figure 7.
</p>
<p>
<img src="img/223.gif" width="515 px"></img>
</p>
<p>
<b>&nbsp;Figure 7</b> Running Time-Plot of Assigned Task Size, From Spinning Brain
</p>
<p>
NetWork's ability to adapt itself to the relative computing power of the partners<br>
provides a natural way to do load balancing. By finding out the relative performance of<br>
the CPUs available and allocating larger tasks to more powerful CPUs, NetWork is able<br>
to effectively balance the work load.
</p>
<h2>DIAGNOSTIC PLOTS FOR THE STATISTICALLY MINDED</h2>
<p>
Read this if you're interested in the details of how we compared the idea the experts<br>
gave us about predicting the hazard-to-leave-idle-state versus our own hunch about<br>
how it might be predicted.
</p>
<p>
The general idea we met with was that usable idle time would be controlled by a<br>
Poisson process, so the idle time would have an exponential distribution. But since an<br>
exponential distribution is memoryless, there would be no chance for optimization<br>
based on waiting times: the hazard-to-leave-idle-state would be constant.
</p>
<p>
To test this idea, we used a special statistical tool-- diagnostic plots. Diagnostic plots<br>
represent statistics&nbsp;&nbsp;in a way that makes their message easy to grasp. A diagnostic plot<br>
is often designed by a statistician in such a way that the significant information shows<br>
up as the deviation of a curve from a straight line, visual information that's easy for<br>
humans to process. To find out whether a certain distribution is exponential, we plot<br>
observed idle times against those that would be expected given an exponential<br>
distribution. If the idle time distribution were in fact near to exponential, this plot<br>
would exhibit a straight line. As you can see in Figure 5, this clearly isn't the case.
</p>
<p>
&nbsp;How we plot the relevant information to test for a&nbsp;&nbsp;Weibull distribution is more<br>
complicated, so we won't go into the details here. (Ask your statistician!) Suffice it to<br>
say that as shown by the fairly linear behavior of the plot in Figure 6, the idle time<br>
distribution is more adequately approximated by a Weibull distribution than by an<br>
exponential distribution.
</p>
<p>
&nbsp;This Weibull distribution has a decreasing hazard rate. For the application this means<br>
that it's helpful to know how long a machine has been idle. In particular, the<br>
hazard-to-leave-idle-state is lower if a machine has been idle for some time.
</p>
<p>
&nbsp;So if you have a chance to select among machines, here's the winner's strategy: choose<br>
the machine that's been idle for the longest time.
</p>
<p>
<img src="img/224.gif" width="353 px"></img>
</p>
<p>
<b>&nbsp;Figure 5</b> Sample Plot Checking for Exponential Distribution
</p>
<p>
<img src="img/225.gif" width="347 px"></img>
</p>
<p>
<b>&nbsp;Figure 6</b> Sample Plot Checking for Weibull Distribution
</p>
<p>
<b>DECIDING BETWEEN RESULTS</b><br>
For the mathematically minded: Assume we have some effective time scale (some<br>
measure of effective iterations done, for example). Assume we have two incoming<br>
partial results <i> Y</i>&nbsp;&nbsp;and <i>Y'</i> , where <i>Y</i>&nbsp;&nbsp;is based on information available at effective time <br>
<i>T</i> , with <i>K</i>&nbsp;&nbsp;iterations done on <i>Y</i> , and <i>Y' </i> is based on information available at time <i>T'</i> ,<br>
with <i>K'</i>&nbsp;&nbsp;iterations. Let <i>Y</i>&nbsp;&nbsp;arrive at time <i>t</i> , <i>Y'</i>&nbsp;&nbsp;at time <i>t'</i>&nbsp;&nbsp;&gt; <i>t.</i>&nbsp;&nbsp;Should we replace the<br>
results of<i>Y</i>&nbsp;&nbsp;by those of <i>Y'</i> ?
</p>
<p>
There are trivial cases: If <i>T'</i>&nbsp;&nbsp;&lt; <i>T</i>&nbsp;&nbsp;and <i>K' </i> &lt; <i>K</i> , then <i>Y' </i> is clearly outdated. Or if <i> T' </i> &gt; <i>T</i> <br>
and <i>K' </i> &gt; <i>K</i> , then <i>Y'</i>&nbsp;&nbsp;is better than <i>Y</i> , so <i>Y</i>&nbsp;&nbsp;should be replaced. Put another way,<br>
results based on better initial information (<i> K'</i>&nbsp;&nbsp;- <i>K</i>&nbsp;&nbsp;&gt; 0) and with better iteration<br>
count (<i>T' </i> - <i>T</i>&nbsp;&nbsp;&gt; 0) can be accepted a priori. Results based on poorer initial<br>
information&nbsp;&nbsp;(<i>K'</i>&nbsp;&nbsp;- <i>K</i>&nbsp;&nbsp;&lt; 0) and with fewer iteration counts (<i> T' </i> - <i>T</i>&nbsp;&nbsp;&lt; 0) can be<br>
rejected a priori. For the remaining cases, a decision must be made. Figure 8 shows<br>
the limits of the acceptance region. The NetWork strategy is to take only those results<br>
that can be accepted a priori.
</p>
<p>
<img src="img/226.gif" width="207 px"></img>
</p>
<p>
<b>Figure 8</b>Limits of Acceptance Region for Results
</p>
<h2>HOW TO IMPLEMENT A NETWORK PROGRAM</h2>
<p>
Now for the good part. You're familiar with the design and operation of NetWork.<br>
Here's your chance to explore how your application might make use of distributed<br>
computing with the help of NetWork. The following discussion will give you a general<br>
idea of how to make your application work with NetWork, but you should study the full<br>
example code included with NetWork on the<i>Developer CD Series</i> disc for a thorough<br>
understanding. 
</p>
<p class="spacer">&nbsp;</p>
<p class="spacer">&nbsp;</p>
<p>
NetWork will communicate with your code by NetWork events. You have to augment<br>
your event- handling code to handle these events. If the what field of the EventRecord is<br>
NetWorkEvt, the message field of the EventRecord will contain a pointer to a NetWork<br>
message. 
</p>
<pre>{******************** The Event Handler *******************}
PROCEDURE DoEvent(Event: EventRecord);
    . . .
    BEGIN
        CASE Event.what OF
        mouseDown:
            DoMouseDown(Event);
        . . .
        {*** You add a case to handle events of type NetWorkEvt. ***}
        NetWorkEvt:
            NetWorkScheduler.HandleMsg(MsgPtr(Event.message));
        . . . app4Evt:
        . . .
        END; {case}
    END;</pre>
<p>
To keep NetWork running, you should give it a chance to fulfill its regular tasks, like<br>
asking you for new jobs or looking for idle workstations. This should be done in your<br>
main event loop. Since we're interested in getting the most from our computing power,<br>
we're using a slightly more elaborate event loop than you'll usually find in the DTS<br>
Sample Code on the CD. We prefer to calculate the next time to call WaitNextEvent in a<br>
more flexible way to get the most from our computing power if our application is<br>
frontmost. The next time to call WaitNextEvent will be kept in a global variable<br>
gNextEventLoopTime. 
</p>
<pre>{******************** The Event Loop ******************}
PROCEDURE MainEventLoop;
    CONST
        cSleep = 0;             {Ticks to wait for wake-up}
        cBackgroundSleep = 20;
        cEventLoopDelay = 1;
              {3 = 1/20 second, recommended interval between
               WaitNextEvents for human interaction. We
               take 1 for faster response.}
    VAR
        newEvent:       EventRecord;    {Event from GetNextEvent}
        hasWNE:         BOOLEAN;
        eventReceived: BOOLEAN;
        mySleep:            LONGINT;

    BEGIN
        hasWNE := system.WNEIsImplemented;
        mySleep := cSleep;  {This is the foreground delay.}
        REPEAT  {Loop until done.}
            IF hasWNE THEN
                BEGIN
                { No mouse moved is wanted, so pass NIL for the
                  mouseRgn.}
                eventReceived := WaitNextEvent(everyEvent, newEvent,
                                               mySleep, NIL);
                UpdateCursor;
                           {Change the cursor shape if appropriate.}
                END
            ELSE
                BEGIN
                SystemTask;     {Let the system do its stuff.}
                UpdateCursor;  
                           {Change the cursor shape if appropriate.}
                eventReceived := GetNextEvent(everyEvent, newEvent);
                END;
            SetEventLoopTime(cEventLoopDelay);
                         {Adjust global variable gNextEventLoopTime.}
            IF eventReceived THEN DoEvent(newEvent)
            ELSE    {No real event, just timeout}
                REPEAT

                    {*** You add the following section. ***}
                    NetWorkScheduler.PeriodicTask;
                        {Allow to generate new tasks.}
                    IF NlTask &lt;&gt; noErr THEN
                       {Try to look up new partners.}
                        ProgramBreak('NlTask Error');
                    mySleep := NetWorkScheduler.GetSleep;
                                            {Adjust sleep value.}
                    {*** End of added section ***}

                    MyTask(BackContinue, mySleep);  {Do local job.}
                UNTIL (gTaskState &lt;&gt; TaskOK) |
                       (LongIntPtr(Ticks)^ &gt;= gNextEventLoopTime);
            IF PAbortFlag THEN gTaskState := TaskCancel;
            {PAbortFlag is a function to check whether the standard
            abort combination has been pressed. gTaskState is a
            global variable where we keep the current state of the
            program.}
            IF gTaskState IN [TaskExit, TaskFatal, TaskAbort] THEN
                gAppDone := TRUE;
        UNTIL gAppDone;
    END; {End of main event loop}</pre>
<p>
Of course, accessing global memory locations like Ticks is bad programming; you<br>
should use TickCount instead. And you shouldn't do direct comparisons<br>
(LongIntPtr(Ticks) ^ &gt;= gNextEventLoopTime); you should use a function to do<br>
comparisons instead. But because this part is in the main loop and we didn't want to<br>
waste any time here, we use this dirty inline comparison. 
</p>
<p>
To start NetWork, you have to generate an instance of the scheduler by calling<br>
new(NetWorkScheduler) and activate it by calling NetWorkScheduler.init.<br>
NetWorkScheduler is defined in the file SchedulerUnit.p that comes with NetWork. If<br>
you've activated or used the scheduler, you should always call NetWorkScheduler.free<br>
before leaving your program. 
</p>
<p>
If you're going to generate subtasks, you have to override the task generator. Take the<br>
prototype definition tTaskGenerator from SchedulerUnit.p and adapt it to your needs.<br>
Create a task generator object and call NetWorkScheduler.InitTaskGenerator to install<br>
it. To customize a task generator, you have to write a function NewTask. NewTask<br>
should return NIL if no subtask can be defined, or a message pointer defining a new<br>
subtask. The proper task definition is private to you.&nbsp;&nbsp;&nbsp;The scheduler's task-sending<br>
activity can be controlled by NetWorkScheduler.SetSending. 
</p>
<p>
If you think of a master-slave setting, you can implement the code for both sides in one<br>
program. At run time, you can use the function Master from the NetWork library to<br>
find out whether you're running as master or as slave. 
</p>
<pre>{**************** Main Routines *******************}
PROCEDURE MyInit; {(VAR TheState : TaskStateType)}
    VAR
    myTaskHandler:      tTaskHandler;
    myMasterTaskHandler: tMasterTaskHandler; {Used for masters only}
    mySlaveTaskHandler: tSlaveTaskHandler;   {Used for slaves only}
    myTaskGenerator:    tMyTaskGenerator;{Typically for masters only}
    myResultHandler:    tReplyResultHandler;
        . . .

    BEGIN
        . . .
        {Initialize the NetWork library.}
        IF InitNetwork(NetWorkEvt) &lt;&gt; noErr THEN fatal;

        {Initialize the name lookup manager.}
        IF NlInit &lt;&gt; noErr THEN fatal;

        {Create and initialize a NetWorkScheduler. Needs a persistent
        memory, so NetWorkScheduler must be a global variable.}
        new(NetWorkScheduler);
        IF NetWorkScheduler = NIL THEN fatal;
        NetWorkScheduler.init; {The scheduler is up and running now.}
        {Create and initialize a handler for incoming messages.}
        IF NetWorkScheduler.Err = noErr THEN
            BEGIN
            IF Master THEN      {Master is defined in NetWorkLib.}
                BEGIN
                new(myMasterTaskHandler);
                myTaskHandler := tTaskHandler(myMasterTaskHandler);
                END
            ELSE
                BEGIN
                new(mySlaveTaskHandler);
                myTaskHandler := tTaskHandler(mySlaveTaskHandler);
                END;
            IF myTaskHandler &lt;&gt; NIL THEN
                NetWorkScheduler.InitTaskHandler(myTaskHandler);
            END; {End of NetWorkScheduler installation}
        . . .
        {Create and initialize a task generator.}
        IF Master THEN
            BEGIN
            new(myTaskGenerator);
            IF myTaskGenerator &lt;&gt; NIL THEN
                NetWorkScheduler.InitTaskGenerator(myTaskGenerator);
            END;
        . . .
    END;</pre>
<p>
Programming for NetWork in general consists of writing a master process (later to be<br>
the client seeking additional computing resources) and a compute server. The compute<br>
server has to be distributed to the coworkers (the additional computing resources that<br>
can be called upon). To guarantee fail-safe behavior, both task generation and<br>
task-handling functions should be implemented on the original generating machine so<br>
that it can operate by itself if need be. These functions must be implemented in the<br>
master process (compute client). Note that to avoid virus proliferation, worms, and<br>
other nasty things, NetWork doesn't do any active transportation of code. The code to be<br>
launched has to reside on the destination machine and is under the control of the<br>
destination owner. 
</p>
<p>
The compute server must be able to accept and handle subtasks. Although it's possible<br>
to use the message-handling system of NetWork directly, we recommend you use the<br>
supplied scheduler model instead. If you're going to accept subtasks, you have to<br>
customize the task handler. Take the prototype definition tTaskHandler and adapt it to<br>
your needs. Create a task handler object and install it by calling<br>
NetWorkScheduler.InitTaskHandler. To customize a task handler, you have to write a<br>
function MsgUsable and a procedure MsgEvaluation. The scheduler will get the priority<br>
information from an incoming message to the PriorityBuffer indicated by MsgPrioPtr.<br>
MsgUsable should check any incoming task on the basis of the header information and<br>
the available priority information. If MsgUsable returns TRUE, the scheduler asks the<br>
message system to pass the bulk of the data describing the subtask to the core buffer<br>
indicated by MsgCorePtr. You have to write a procedure MsgEvaluation to take the data<br>
from the buffer and initiate the proper task execution. To return a result to the<br>
sender, you can make use of the ReplyMessage function. 
</p>
<p>
With NetWork, programs can be launched automatically on remote request. Programs<br>
launched on remote request may be terminated by NetWork when the owner accesses<br>
the machine. Don't assume it's safe to continue processing at that time if you receive a<br>
Command-Q. You must clean up as soon as possible or you won't have another chance.<br>
Also note that you don't have the time to report results, because all<br>
messages--including those about to be transferred--are killed when your application<br>
dies. Remember that NetWork's priority is with the owner, not with your application.<br>
The only way to override this is to control the process class of your application. If it's<br>
necessary to clean up, set your process type to master after program initialization and<br>
call the Idle function regularly. But be forewarned that users may become annoyed at<br>
having an alien application around, and your application will likely be removed from<br>
the list of welcome visitors. 
</p>
<p>
<b>RISKS IN DISTRIBUTED COMPUTING</b><br>
Anyone working in distributed computing should be aware of the risks involved in a<br>
distributed system. Such risks include those relating to competition for resources as<br>
well as those relating to security. 
</p>
<p>
<b>COMPETITION FOR RESOURCES</b><br>
Any distributed computing system competes for computing and communication<br>
resources. NetWork has been designed to minimize the impact of this competition on<br>
priority users. Still, the version of NetWork currently distributed uses the AppleTalk<br>
Name-Binding Protocol (NBP) to register and look up idle stations, and the AppleTalk<br>
NBP is prone to impose a cumulative load that increases with the square of the number<br>
of workstations. This will create a problem if the number of workstations in the<br>
network is very large. The version of NetWork in distribution won't impose a big load<br>
if used in networks with up to 100 workstations. If you do have more workstations in<br>
your local zone, please consult the<i>NetWork Programmer's Guide</i> for suggestions--our<br>
research version scales linearly to accommodate up to 10,000 workstations. If you<br>
have more than 10,000 Macintosh computers, we'll have to invest some additional<br>
thinking, which we'll gladly do. 
</p>
<p>
Distributed computing systems can also compete for disk space with priority users.<br>
This is a crucial point for UNIX-based systems. On a UNIX-based system you can send a<br>
guest process to the background, but this still may result in a swapping behavior<br>
that's a nuisance to the priority user (unless you're using Mach). For NetWork, we<br>
decided to kill any guest process if the priority user returns, so NetWork doesn't<br>
compete for disk space. 
</p>
<p>
<b>SECURITY CONSIDERATIONS</b><br>
Other risks relate to the security of code and information. Just as programs and data<br>
can carry viruses into a machine from the outside, so distributed computing guests can<br>
bring in something undesirable.&nbsp;&nbsp;&nbsp;When you grant access to another user, you never<br>
know whether you're enabling the importation of a Trojan horse. For the present, we<br>
don't see any way to guarantee system security under conditions of distributed<br>
computing, so we've chosen two ad hoc actions to improve security. 
</p>
<p>
First, we refrain from code migration. Of course, it would be most convenient to make<br>
use of a remote machine without any assumptions about the availability of code on that<br>
machine, and we'd love to do this. But this would require moving executable code if<br>
necessary or training the receiving machine on the job. Because we don't see any way<br>
to check whether that code contains a virus, the code to be executed is required to be<br>
already available to the host machine. Furthermore, NetWork assumes that an access<br>
path is denoted on the host machine and launches only applications resting in this<br>
trusted path. This path may direct code to a server, and the usual access control<br>
mechanisms apply. 
</p>
<p>
Second, we include with NetWork an example called RemoteJob, designed to educate<br>
users about the risk of allowing remote execution of powerful code like MPW. Even if<br>
there's no virus attached to the code of MPW, it's powerful enough to allow you to<br>
compile new programs, viruses and all.&nbsp;&nbsp;&nbsp;The point of including this example is to<br>
forewarn you of this possibility. RemoteJob takes commands from the sending station,<br>
passes them to the recipient, and launches the MPW shell there if it can be found in the<br>
trusted path. The default example passes a "beep" command to MPW, but it could just<br>
as well get MPW to compile a virus and install it on the fly. The moral of the<br>
story:<i>Never put a shell or any powerful tool in the trusted access path. </i>
</p>
<p>
<b>BACK FROM THE FUTURE</b><br>
After reading this article you should have a good idea of the possibilities and challenges<br>
that are bound to confront programmers with the advent of distributed computing.<br>
These possibilities and challenges are already being actively explored in some<br>
quarters. In particular, the NetWork model of distributed computing has already been<br>
used in a variety of applications. Some examples: a distributed file system using<br>
NetWork was built at the University of East Anglia; a U.S. company used NetWork to<br>
implement a distributed rendering system; and an IBM subsidiary in France is using<br>
NetWork for distributed compilation/program construction. But for most of the world,<br>
the distributed computing wave is still just out there on the horizon. We need to begin<br>
playing with and prototyping applications<i>now</i>&nbsp;&nbsp;with distributed computing in mind, so<br>
that when system support arrives, we'll know how to use it. In sum, the time we spend<br>
experimenting with NetWork now is sure to pay off in the not-too-distant future when<br>
the distributed computing wave comes rolling in.
</p>
<p>
<b>CHEAP THRILLS: USING NETWORK'S SERVICES</b><br>
Even if you don't plan to implement a NetWork system, you might find some of<br>
NetWork's services very useful indeed. If you install the NetWork Processor, you can<br>
make use of any NetWork service. For example, you can ask NetWork whether your<br>
station is to be considered idle instead of implementing all the code yourself.
</p>
<p>
<b>THRILL 1: USING THE IDLE MONITOR TO HELP YOU EXECUTE A BIG JOB</b><br>
Move the NetWork Processor into your System Folder and reboot your Macintosh.<br>
Modify your code to include NetWork.p and link to NetWorkLib.o.
</p>
<p>
Add the following line to your initialization code:
</p>
<pre>myErr := InitNetWork(NetWorkEvent);</pre>
<p>
Add the following line to the idle branch of your main event loop:
</p>
<pre>IF Idle THEN DoNextRoundOfMyGreatBigJob;</pre>
<p>
DoNextRoundOfMyGreatBigJob is executed whenever NetWork considers your machine<br>
to be idle.
</p>
<p>
A word of warning: If DoNextRoundOfMyGreatBigJob is compute intensive, this will<br>
move your machine to the busy state, so "WHILE Idle DO . . . " would not be a good idea.
</p>
<p>
<b>THRILL 2: USING THE IDLE MONITOR TO LAUNCH AN IDLE TASK</b><br>
Move the NetWork Processor into your System Folder. Create a folder named NetWork<br>
Idle Tools in your System Folder. Move your application into NetWork Idle Tools. Your<br>
application will be launched whenever NetWork considers your machine to be idle.<br>
Note that because NetWork will kill any application it has launched when the state of<br>
the machine changes to busy, this use of the idle monitor makes sense only for turnkey<br>
applications such as screen savers. (See the ScreenSaver example provided with<br>
NetWork.)
</p>
<p>
As NetWork has a chance to learn that the application is not a user-initiated process,<br>
the machine will stay in the idle state (in contrast to Thrill 1).
</p>
<p>
<b>THRILL 3: USING THE COMMUNICATION&nbsp;&nbsp;SYSTEM</b>Move the NetWork Processor<br>
into your System Folder. Modify your code to include NetWork.p and link to<br>
NetWorkLib.o.
</p>
<p>
Add the following line to your initialization code:
</p>
<pre>myErr := InitNetWork(NetWorkEvent);</pre>
<p>
Add the line
</p>
<pre>MyHandleMsg(MsgPtr(Event.message));</pre>
<p>
to your main event loop, like so:
</p>
<pre>CASE Event.what OF
    mouseDown:
        DoMouseDown(Event);
    . . .
    NetWorkEvt:
        MyHandleMsg(MsgPtr(Event.message));</pre>
<p>
Your application will now receive messages from NetWork. You'll have to write the<br>
MyHandleMsg procedure to evaluate the messages. Message format and support<br>
routines are documented in the <i> NetWork Programmer's Guide.</i>
</p>
<p>
<b>REFERENCES AND FURTHER READING</b>
</p>
<ul>
<li>"Asynchronous Iteration" by W. F. Eddy and</li>
<li>J. Schervish, <i>Computing Science and Statistics: Proceedings of the 20th</i><br>
<i>Symposium on the Interface, 1987</i>&nbsp;&nbsp;(American Statistical Association,<br>
1988), pages 165-173.</li>
<li>"Asynchronous Iterative Methods for Multiprocessors" by G. M. Baudet,<br>
<i>Journal of the ACM </i> (1978), pages 226-244.</li>
<li><i>Brains, Machines, and Mathematics</i>  by M. A. Arbib (Springer, 1987).</li>
<li>"DPUP: A Distributed Processing Utilities Package" by T. J. Gardner, I. M.<br>
Gerard, C. R. Mowers, E. Nemeth, and R. B. Schnabel, <i>ACM SIGNUM</i><br>
<i>Newsletters </i> (1986, Issue 4), pages 5-19.</li>
<li>"Finding Idle Machines in a Workstation-Based Distributed System" by M.<br>
T. Theimer and K. A. Lantz,<i>IEEE Transactions on Software Engineering </i><br>
(November 1989), pages 1444-1457.</li>
<li><i>NetWork Communications</i>  by J. Lindenberg (Universit&auml;t<br>
Karlsruhe, Institut f&#220;r Betriebs und Dialogsysteme, 1990). Republished on<br>
the current <i>Developer CD Series</i>&nbsp;&nbsp;disc.</li>
<li><i>NetWork Programmer's Guide</i>  by G. Sawitzki (Universit&auml;t<br>
Heidelberg, Institut f&#220;r Angewandte Mathematik, 1990, 1991). Republished<br>
on the current <i>Developer CD Series</i>&nbsp;&nbsp;disc.</li>
<li><i>Parallel and Distributed Computation </i> by</li>
<li>P. Bertsekas and J. N. Tsitsiklis (Prentice-Hall, 1989).</li>
<li>"Primitives for Distributed Computing in a Heterogeneous Local Area<br>
Network Environment" by G. Bernard, A. Duda, Y. Haddad, and G. Harrus, <i>IEEE</i><br>
<i>Transactions on Software Engineering </i> (December 1989), pages 1567-1578.</li>
<li>"Spinning Brain: An Interactive Program for the Associative Recall of<br>
Visual Patterns" by R. K&#220;hn and G. Sawitzki, <i>Wheels for the Mind (Europe) </i><br>
(Apple Computer, Inc., January 1989).</li>
<li><i>The TRON Project, 1988: Proceedings of the Fifth TRON Project</i><br>
<i>Symposium</i>&nbsp;&nbsp;edited by K. Sakamura (Springer, 1989).</li>
</ul>
<p>
<b>G&#220;NTHER SAWITZKI </b>sold his car seven years ago and hasn't regretted it for a second<br>
since then. He thinks that cars, along with sports (except for art forms like aikido),<br>
are relics of the past. He works (within walking distance of home) at the University of<br>
Heidelberg's Institute for Applied Mathematics, doing computational statistics and data<br>
analysis when he's not busy with software engineering and development. He headed the<br>
NetWork Project and designed the basis of NetWork. In his opinion, Aldous Huxley's<br>
<i>Brave New World</i>&nbsp;&nbsp;is a vital book of immediate importance. His favorite game is go<br>
("It's the only game that allows me to comprehend that it's a game"), his favorite food<br>
is mousse au chocolat (with white and black chocolate), and his favorite time of day is<br>
tomorrow. *
</p>
<p>
<b>For more on the TRON Project, </b> see <i>The TRON Project, 1988: Proceedings of the</i><br>
<i>Fifth TRON Project Symposium.</i>&nbsp;&nbsp;*
</p>
<p>
<b>Numerical methods that can be formulated as Lipschitz contractions </b> are<br>
discussed in Part 2 of <i> Parallel and Distributed Computation</i>&nbsp;&nbsp;by D. P. Bertsekas and J.<br>
N. Tsitsiklis.<b> *</b>
</p>
<p>
<b>Hopfield nets </b>are described in more detail in "Spinning Brain: An Interactive<br>
Program for the Associative Recall of Visual Patterns" by R. K&#220;hn and G. Sawitzki and<br>
in Chapter 5 of <i> Brains, Machines, and Mathematics</i>&nbsp;&nbsp;by M. A. Arbib.<b>*</b>
</p>
<p>
<b>The signature you use </b>when you experiment with NetWork should be NetE (this<br>
spelling). This signature has been registered with Apple by the NetWork Project and<br>
is reserved for experimental use. *
</p>
<p>
<b>Further details on customizing the task generator </b>are given in the <i> NetWork</i><br>
<i>Programmer's Guide</i> .
</p>
<p>
<b>*Further details on customizing the task handler </b> are given in the <i> NetWork</i><br>
<i>Programmer's Guide</i> .<b>*</b>
</p>
<p>
<b>THANKS TO OUR TECHNICAL REVIEWERS </b>Michael Gough, Larry Taylor, Peter<br>
Zukoski*
</p>
<p>
<b>FURTHER CREDITS</b> Studying asynchronous iterations in a nonguaranteed (random)<br>
environment was suggested by the paper by&nbsp;&nbsp;W. F. Eddy and M. J. Schervish entitled<br>
"Asynchronous Iteration." W. Rheinboldt suggested the scheduler strategy of accepting<br>
only those packages that can be accepted a priori. The NetWork communication system<br>
was designed and implemented by J. Lindenberg.&nbsp;&nbsp;The NetWork software and<br>
documentation is&nbsp;&nbsp;&#169; 1989-1992 The NetWork Project, StatLab Heidelberg. NetWork<br>
is free for personal, noncommercial use. The most recent version can be accessed on<br>
Internet from StatLab.uni-heidelberg.de[129.206.113.100].<b> *</b>
</p>
</body>
</html>
