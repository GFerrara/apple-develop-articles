<html>
<head>
<!-- Article ID: 6 - Extracted from develop-1993 -->
<!-- on 2024-02-03 by Giorgio Ferrara - giorgio<dot>ferrara<at>gmail<dot>com -->
<!-- The content is protected by the copyright of its respective owners -->
<title>March 93 - THE VETERAN NEOPHYTE</title>
<link href="../common/styles/main.css" rel="stylesheet" type="text/css">
</head>
<body>
<h2>THE VETERAN NEOPHYTE</h2>
<h2>TOWER OF BABBLE</h2>
<h1>DAVE JOHNSON</h1>
<p>
<img src="img/131.gif" width="180 px"></img>
</p>
<p>
&nbsp;I recently started learning MacApp. (I know, I know, I can see you shaking your great<br>
shaggy collective head, chuckling to yourself, asking where I was three years ago when<br>
MacApp was still news. Let's just say I'm a late bloomer.) People weren't kidding when<br>
they said that the learning curve is long and steep. They also weren't kidding when they<br>
said that it's absolutely worth it. 
</p>
<p>
&nbsp;For me, it was a double whammy: learning MacApp <i>and </i>transitioning from THINK C to<br>
MPW.&nbsp;&nbsp;&nbsp;(See, if I'd only learned it in the MacApp 2.0 days I could have used THINK<br>
Pascal, but noooo, I had to wait till now.) I've been using THINK C for virtually all my<br>
programming since 1986 or so. Using MPW for my own little exploratory projects<br>
would be like calling in a highly trained, ultramodern, rapid- deployment mobile<br>
emergency medical team to remove a splinter from my thumb. The job would get done,<br>
and beautifully, but it'd be an absolutely colossal waste of time, effort, and expense.&nbsp;&nbsp;<br>
Frankly, I'd rather just have a good pair of tweezers. 
</p>
<p>
&nbsp;But alas, if I want to use MacApp (and I do!) the days of coding on my PowerBook 100<br>
in the backyard with loyal hounds lolling at my feet are gone for good. Now I need 16<br>
MB of RAM minimum and at<i>least</i>40 MB of hard disk space (120 to be really<br>
comfortable). And I'm not even going to<i> mention</i>MacApp compile times; it hurts me too<br>
much. 
</p>
<p>
&nbsp;But all that's really just logistics and can be gotten used to pretty quickly. The real<br>
difference is in the very nature of my interaction with the machine: It used to be that<br>
when I'd think of something that needed doing, I'd just go do it. It was like building a<br>
machine from scratch, piece by handcrafted piece. Now, using MacApp, when I think of<br>
something that needs doing I conduct massive, cross- referenced searches through<br>
megabytes of source code to figure out where it's already been done, because no doubt<br>
somebody already thought of it, or something very much like it, and implemented it<br>
better than I ever could. It's as though I'm running around on top of a giant, humming<br>
machine that stretches to the horizon on all sides, hunting for just the right place to<br>
reach down into the dark recesses, pull up a live, vibrating cable, and splice in my<br>
little special-purpose unit. Often I've spent an hour hunting around for the right place<br>
to insert some code, only to discover that to do what I want I just need to set the value<br>
of some out-of-the-way Boolean deep inside an object's remote ancestor. 
</p>
<p>
&nbsp;Well, I could ramble forever about my learning experiences, but those of you who've<br>
been there know all about it, and those of you who haven't probably don't want to hear<br>
it. But this is the first time since I discovered the Macintosh and switched from FORTH<br>
to C that the<i>feel</i>of programming has been completely transformed for me. It occurred<br>
to me that the fact that programming is the kind of thing that can<i>have</i> a feeling to it is<br>
noteworthy.&nbsp;&nbsp;Programming computers is an activity unlike any other. It's a<br>
human-machine interaction, but because the machine is very special, interacting with<br>
it is also very special. Programming has a depth that other machine interactions don't,<br>
so it can assume qualities not normally associated with the operation of machinery. It<br>
can be a creative act, akin to building an intricate, glittering crystal clockwork out of<br>
gossamer strands of pure thought; and it can also be formidable drudgery, a mountain<br>
of mind-numbing details, endless in their intricacy, interrelatedness, and total<br>
irrelevance to the real task at hand. These are not normally the kinds of things you'd<br>
say about operating your dishwasher or toilet. 
</p>
<p>
Computers are something truly new on earth. They're machines that can simulate any<br>
other machine; they're somehow potentially<i>every</i>machine in one. A well-known<br>
computer luminary put it this way:
</p>
<p>
<i>&nbsp;It [the computer] is a medium that can dynamically simulate the details of any other</i><br>
<i>medium, including media that cannot exist physically. It is not a tool, although it can</i><br>
<i>act like many tools. It is the first metamedium, and as such it has degrees of freedom</i><br>
<i>for representation and expression never before encountered and as yet barely</i><br>
<i>investigated.&nbsp;&nbsp;</i> -- Alan Kay, "Computer Software,"<i>Scientific American</i>, September<br>
1984. 
</p>
<p>
Other machines are physical extensions of ourselves; they let us sense and manipulate<br>
our physical world with more power and flexibility than we can by ourselves. But<br>
they're just<i>physical</i>extensions.&nbsp;&nbsp;&nbsp;Computers, though, manipulate and embody<br>
abstractions and symbols; they operate on patterns of electrical activity, on<br>
imagination, on mindstuff.&nbsp;&nbsp;If you can imagine a machine or a medium in detail, you can<br>
program a computer to simulate it. So programming computers is much, much more<br>
than telling them what to do -- it's telling them what to<i> be</i>.
</p>
<p>
Of course, all this philosophical and poetic mumbo-jumbo crashes to the ground when<br>
faced with reality. Try telling my friend Michele -- who wrote an entire book on her<br>
Macintosh SE and just recently realized that she can use Standard File dialogs to<br>
navigate her hard disk -- that her computer "has degrees of freedom for<br>
representation and expression never before encountered." Yeah, right. Admittedly, the<br>
computer is much more fluid-seeming to programmers than to users (someday,<br>
hopefully, a moot distinction), but there's still a large discrepancy between the<br>
promise and the realization. Computers still feel more like erector sets -- lots of<br>
hard, inflexible little parts -- than like clay. 
</p>
<p>
Boiled down to its thick, syrupy essentials, computer programming is quite simply the<br>
creation and communication of detailed instructions. The creation is the really exciting<br>
part, and is (or should be) the main task. But the communication is what really<br>
defines the experience of programming; it's the part that has a<i>feel</i>to it. 
</p>
<p>
All this touchy-feely talk smacks of natural language. Are programming languages<br>
really just another class of natural languages? Is that why programming can feel so<br>
rich? I found a great book that addressed this very question (among others):<i>The</i><br>
<i>Cognitive Connection</i>by Howard Levine and Howard Rheingold. 
</p>
<p>
Programming languages and natural languages do indeed have deep similarities, and<br>
share essential features found in any language. They're both sets of abstract symbols<br>
that have meaning only by mutual agreement between communicating parties. They're<br>
both open-ended: they have an underlying structure and system of rules that allow an<br>
infinite variety of correct sentences to be constructed. (Even more remarkably, any<br>
correct sentence can later be deciphered by anyone who knows the language, even<br>
though they've never seen that sentence before.)
</p>
<p>
Linguists say that a language has three parts: phonology, syntax, and semantics.<br>
Phonology is the way a language is turned into sounds, and is irrelevant to<br>
programming languages since they're never spoken. Syntax is the set of rules that<br>
specify how the parts of the language -- words and phrases -- are put together to<br>
form sentences. Programming languages obviously have strict and unforgivingsyntax.<br>
But syntax by itself is an empty shell, telling us only whether a sentence is well<br>
formed, not what it means. That's the function of semantics. 
</p>
<p>
Ah, sweet semantics! This is where the rubber meets the road, linguistically speaking,<br>
and where significant differences between natural languages and programming<br>
languages begin to appear.&nbsp;&nbsp;&nbsp;Howard and Howard illustrate one big semantic difference<br>
between natural languages and programming languages by comparing their<br>
dictionaries. (Dictionaries are, in a sense, the embodiment of a language's semantics.)
</p>
<p>
Natural language dictionaries are written in natural languages, so the language must be<br>
rich and flexible enough to describe itself. When you look up an English word in<br>
Webster's, you get a definition written in English. This is only possible because words<br>
in natural languages can have more than one meaning.
</p>
<p>
Programming language dictionaries, on the other hand, are never written in a<br>
programming language. When you look up the definition of a Pascal word, the<br>
description is written in English (or Portuguese or Swahili or whatever), not Pascal<br>
or C++ or LISP. Unfortunately, the duplicity of meaning that allows a natural language<br>
to describe itself opens the door to paradox and self- contradiction, something<br>
programming languages can't tolerate. 
</p>
<p>
But there's another, even more apparent semantic difference between programming<br>
languages and natural languages. As the Howards so aptly put it:
</p>
<p>
<i>&nbsp;. . . although philosophers and linguists have struggled for centuries to give precise</i><br>
<i>meaning to the word "meaning," you don't need a degree in either discipline to realize</i><br>
<i>that what constitutes meaning for a programming language is dramatically different</i><br>
<i>from what constitutes meaning for a natural language. </i>
</p>
<p>
Semantically, programming languages are only a sort of horribly stunted subset of<br>
natural languages, because the world they describe -- the operations of computers --<br>
is only a sort of horribly stunted subset of the natural world. So "conversations" in a<br>
programming language aren't conversations at all; they're one-sided and<br>
one-dimensional commands whose conversational interest is on a par with the<br>
instructions on the back of a shampoo bottle: Lather, rinse, repeat. 
</p>
<p>
We are, of course, in the infancy of our relationship with computers, still drooling<br>
and babbling experimentally most of the time. Look at MacApp: compared to other<br>
available methods of programming the Macintosh, it's astoundingly elegant and<br>
streamlined, but even MacApp's most vocal devotees don't want to stop there. Far from<br>
being the end product of the evolution of programming, MacApp is only one of the first<br>
teetering steps toward more natural and more fluent communication with computers. 
</p>
<p>
A big question is whether our interactions with computers will<i>ever</i> be totally fluent,<br>
where fluency means the complete subsumption of syntax, so that we can go directly<br>
from meaning to expression with no conscious effort. Some people insist it will<br>
happen, that there's a future of instant, effortless communication with computers, a<br>
wide and crystal clear pathway between us and them, but somehow I can't buy it.&nbsp;&nbsp;I<br>
suspect that instead, computer communication will just get more and more like<br>
natural communication. 
</p>
<p>
Fraught with misunderstanding and misinterpretation, blocked by its implicit<br>
awkwardnesses and incompleteness, human language is nevertheless rich beyond depth.<br>
Its infinite flexibility allows it to carry and contain the full spectrum of human<br>
thought and feeling, and provides a ground for endless creativity. Indeed, there is an<br>
intense joy to using language --<i>any</i>language -- well. If we get only half as far with<br>
our computers as we have with our words, we'll have come a very long way indeed. 
</p>
<h2>RECOMMENDED READING</h2>
<ul>
<li><i>The Cognitive Connection </i>by Howard Levine and Howard Rheingold<br>
(Prentice-Hall Press, 1987).</li>
<li><i>Scientific American,</i> September 1984.</li>
<li><i>The Happy Birthday Present </i>by Joan Heilbroner, pictures by Mary<br>
Chalmers (Harper &amp; Row, 1962).</li>
</ul>
<p>
<b>DAVE JOHNSON </b>recently bought some Crash Dummies and peripheral equipment.<br>
These are little "action figures," modeled after real crash dummies, that fly apart in<br>
various ways upon impact. You can buy a car to crash them in, crash dummy pets<br>
(named Bumper and Hubcat), crash dummy babies in strollers or car seats, crash<br>
dummy pedestrians, and even a crash dummy torture chair with straps and clamps and<br>
cranks to pull the dummies apart more slowly, one limb at a time. Dave is convinced<br>
that if he preserves all the parts in their original packaging he can sell them for some<br>
huge amount of money in the future, or at least that's how he's justifying the expense.<br>
*
</p>
<p>
<b>Dave welcomes feedback</b> on his musings. He can be reached at JOHNSON.DK on<br>
AppleLink, dkj@apple.com on the Internet, or 75300,715 on CompuServe.*
</p>
</body>
</html>
