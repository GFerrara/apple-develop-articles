<html>
<head>
<!-- Article ID: 53 - Extracted from develop-1993 -->
<!-- on 2024-02-27 by Giorgio Ferrara - giorgio<dot>ferrara<at>gmail<dot>com -->
<!-- The content is protected by copyright of their respective owners -->
<title>December 93 - MAKING THE LEAP TO POWERPC</title>
<link href="../common/styles/main.css" rel="stylesheet" type="text/css">
</head>
<body>
<h2>MAKING THE LEAP TO POWERPC</h2>
<h1>DAVE RADCLIFFE</h1>
<p>
<img src="img/273.gif" width="180 px"></img>
</p>
<p>
<i>Apple will soon be introducing the first Macintosh CPU architecture not based on a</i><br>
<i>68000-family microprocessor. The entirely new architecture is built around a new</i><br>
<i>RISC CPU -- the PowerPC microprocessor jointly designed by IBM, Motorola, and</i><br>
<i>Apple. Truly taking advantage of PowerPC technology will require an ongoing effort by</i><br>
<i>both Apple and developers. Apple is making the first leap to this new platform; now it's</i><br>
<i>up to developers to make the next leap and bring the performance made possible by</i><br>
<i>PowerPC technology to their applications.</i>
</p>
<p class="spacer">&nbsp;</p>
<p>
In 1984, Apple Computer offered a startling vision of the future of personal<br>
computing by introducing the Macintosh, which radically changed the desktop. Now,<br>
nearly ten years later, the computing world embraces graphical interfaces. Ten years<br>
is a lifetime in computing terms; at that age, many computing architectures are<br>
considered ancient. The Macintosh enters its second decade by looking to the future<br>
while remembering its past -- making the transition from the sturdy Motorola<br>
68000 family to the sleek new PowerPC processor-based family without forsaking<br>
developers and users and their investment in the 680x0 architecture. 
</p>
<p>
The PowerPC microprocessor is the most significant change to date in the Macintosh<br>
product line.&nbsp;&nbsp;&nbsp;This article introduces the new PowerPC architecture and discusses the<br>
ramifications for existing applications, as well as opportunities for new or revised<br>
applications to take full advantage of the power of the new chip. It contrasts the new<br>
architecture with the old and explains how this new architecture both acknowledges<br>
the past and prepares for the future. 
</p>
<h2>COMPARING CISC AND RISC</h2>
<p>
&nbsp;Much has been written about the differences between a CISC (complex instruction set<br>
computer) architecture, used in Motorola's MC680x0 processors, and a RISC (reduced<br>
instruction set computer) architecture, used in the PowerPC microprocessor. The<br>
relative merits of the two architectures have also been widely debated. A detailed<br>
discussion of CISC and RISC is beyond the scope of this article, but some understanding<br>
of RISC principles is useful for understanding PowerPC architecture. 
</p>
<p>
Two logical considerations motivated CISC development. The first was a desire to<br>
simplify assembly-language programming by enriching the functionality of the<br>
instruction set. CISC architectures did this by providing a greater variety of<br>
instructions, as well as a wide array of addressing modes, thereby reducing the<br>
number of steps required to perform a particular operation.&nbsp;&nbsp;&nbsp;Second, as writing<br>
compilers became easier, there was a desire to provide instructions more closely<br>
related to operations performed by high-level languages. CISC architectures were<br>
marvelously successful at satisfying this goal also.&nbsp;&nbsp;In the early 1980s, hardware<br>
designers began to run into the limitations inherent in CISC architectures,<br>
particularly in their ability to streamline the flow of instructions. At the same time,<br>
the software world was deemphasizing assembly-language programming in favor of<br>
high-level languages with sophisticated, optimizing compilers. This allowed hardware<br>
designers to simplify their architecture and shift much of the performance burden to<br>
compiler writers. 
</p>
<p>
            The classic equation for execution time is
        </p>
        <p>
            <div style="display: inline-block;">
                <math display="block">
                    <mrow>
                        <mi>ET</mi>
                        <mo>=</mo>
                        <munderover>
                            <mo>&Sum;</mo>
                            <mrow>
                                <mi>i</mi>
                                <mo>=</mo>
                                <mn>1</mn>
                            </mrow>
                            <mi>N</mi>
                        </munderover>
                        <mrow>
                            <msub>
                                <mi>CP</mi>
                                <mn>i</mn>
                            </msub>
                            <mo>*</mo>
                            <mi>CT</mi>
                        </mrow>
                    </mrow>
                </math>
            </div>
        </p>
        <p>
        
where <i>ET</i> is the total execution time, <i>N</i> is the<br>
number of instructions executed, <i>CPI</i> is the number of cycles per instruction, and <i>CT</i> is<br>
the cycle time. Both CISC and RISC architectures benefit from reduced cycle time.<br>
Faster clock rates translate directly to smaller cycle times, and hence shorter<br>
execution times. Where CISC and RISC architectures differ is in their approach to <i>N</i> and<br>
CPI. CISC tries to shorten execution times by minimizing <i>N</i>, while RISC tries to<br>
minimize <i>CPI</i>. 
</p>
<p>
<b>PIPELINING</b><br>
The four typical stages in executing an instruction are fetch, decode, execute, and<br>
write. In a simplistic architecture, these stages all happen in sequence, and the next<br>
instruction can't start until the previous instruction has finished, as shown in Figure<br>
1. Designers realized that this need not be the case and that each of these stages can<br>
overlap.&nbsp;&nbsp;&nbsp;Once an instruction is fetched and passed to the decode stage, the next<br>
instruction can be fetched without waiting for the first instruction to complete. This<br>
technique, known as <i>pipelining</i>, is shown in Figure 2. 
</p>
<p>
The example in Figure 2 executes the same two instructions, but in only nine cycles,<br>
compared to 12 cycles in the nonpipelined case. There's a curious thing about this<br>
example, though: the second instruction takes eight cycles to complete when pipelined,<br>
but only five when it's not. This is because the various stages take different amounts of<br>
time to complete. The overall result is better, but unnecessary delays can occur in<br>
instruction execution. 
</p>
<p>
<img src="img/274.gif" width="572 px"></img>
</p>
<p>
<b>Figure 1 </b>Nonpipelined Stages of Execution
</p>
<p>
<img src="img/275.gif" width="449 px"></img>
</p>
<p>
<b>Figure 2 </b>Pipelined Stages of Execution
</p>
<p class="spacer">&nbsp;</p>
<p class="spacer">&nbsp;</p>
<p class="spacer">&nbsp;</p>
<p class="spacer">&nbsp;</p>
<p>
Variable numbers of cycles per stage is a characteristic of CISC architectures.<br>
Complex instructions may occupy multiple words, requiring multiple cycles to fetch.<br>
Multiple operands complicate the process of decoding. More complicated instructions<br>
take longer to execute than simpler instructions.&nbsp;&nbsp;&nbsp;In Figure 2, the execute stage of the<br>
second instruction is delayed two cycles while waiting for the first instruction to<br>
execute. This is known as a pipeline <i>stall</i>. Similarly, the write stage sits idle for one<br>
cycle between the first and second instructions while waiting for the execute stage of<br>
the second instruction to complete. This is known as a pipeline <i>bubble</i>. Both stalls and<br>
bubbles reduce the efficiency of the pipeline and increase the overall number of cycles<br>
per instruction. 
</p>
<p>
<b>INCREASING PIPELINE EFFICIENCY</b><br>
RISC architectures work very hard to eliminate inefficiencies in the instruction<br>
pipeline and keep the pipeline jammed full. RISC architectures share most or all of the<br>
following common features:
</p>
<ul>
<li>Instructions are a uniform length. Variable-length instructions in CISC<br>
architectures mean that time must be spent just figuring out how long the<br>
instruction is and how many operands it uses. RISC architectures don't have<br>
that problem. </li>
<li>Simplified instructions, instruction formats, and addressing modes allow<br>
for fast instruction decoding and execution. </li>
<li>Relatively large numbers of registers and large amounts of fast-cache<br>
memory reduce cycles spent for access to slower, main memory and allow<br>
frequently used variables to be kept loaded. </li>
<li>Load/store architecture is used for access to memory. The only<br>
memory-to- register and register-to-memory operations are load and store<br>
instructions. All other operations are register only. Register-to-memory and<br>
memory-to-memory operations in CISC architectures require multiple cycles<br>
to complete. </li>
<li>Instructions are simple. In an ideal RISC machine, each stage requires one<br>
cycle to complete. </li>
<li>For improved performance, instructions can be implemented directly in<br>
hardware instead of being microprogrammed as in CISC processors. </li>
</ul>
<p>
Figure 3 shows an example of executing instructions on a nonpipelined RISC machine.<br>
When instructions are not pipelined, they complete serially, with two instructions<br>
completing in eight cycles. The optimal case for pipelining instructions is shown in<br>
Figure 4. Now you have the two instructions executing in just five cycles. If the<br>
pipeline is kept full like this, the number of cycles per instruction drops to just one.<br>
This is the goal of most RISC architectures.
</p>
<p>
<img src="img/276.gif" width="413 px"></img>
</p>
<p>
<b>Figure 3 </b>RISC Nonpipelined Stages of Execution
</p>
<p>
<img src="img/277.gif" width="293 px"></img>
</p>
<p>
<b>Figure 4 </b>RISC Pipelined Stages of Execution
</p>
<p class="spacer">&nbsp;</p>
<p class="spacer">&nbsp;</p>
<p class="spacer">&nbsp;</p>
<p class="spacer">&nbsp;</p>
<p>
One cycle per instruction is the ideal case for this example, but in reality, stalls and<br>
bubbles occur, even in the best architectures. This is where the compiler comes into<br>
play. The compiler has detailed knowledge of how the program should work. It need not<br>
perform operations in the order specified in the source code; it need only guarantee<br>
that the right result is obtained. If you build into the compiler some knowledge of how<br>
to make best use of the CPU, the compiler can make a huge difference in program<br>
performance. 
</p>
<p>
Consider the following two C instructions:
</p>
<p>
<code>b = *a + 5;</code><br>
<code>d = *c + 10;</code>
</p>
<p class="spacer">&nbsp;</p>
<p>
The variables <i>a, b, c,</i> and <i>d</i> are all long or pointer-to-long variables. The compiler<br>
might generate the following assembly instructions on the PowerPC microprocessor:
</p>
<p>
<code>lwz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r5,0(r3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;; Load value pointed to by r3 into r5</code><br>
<code>addi&nbsp;&nbsp;&nbsp;&nbsp;r5,r5,0x0005&nbsp;&nbsp;&nbsp;&nbsp;; Add 5 to value in r5</code><br>
<code>lwz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r6,0(r4)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;; Load value pointed to by r4 into r6</code><br>
<code>addi&nbsp;&nbsp;&nbsp;&nbsp;r6,r6,0x000a&nbsp;&nbsp;&nbsp;&nbsp;; Add 10 to value in r6</code>
</p>
<p class="spacer">&nbsp;</p>
<p>
The <b>lwz</b> instruction (Load Word and Zero) loads a register from a source value. On a<br>
PowerPC processor, words are 32-bit values; 16-bit values are half words.<br>
The <b>addi</b> instruction (Add Immediate) adds the immediate value and stores the result. 
</p>
<p>
Figure 5 shows what happens when these instructions execute. Both <b>addi</b> instructions<br>
stall in the decode stage because they can't enter the execute stage until the register is<br>
available from thelwzinstruction. 
</p>
<p>
The compiler can prevent the stalls. Instead of following the flow of the original source<br>
code, you can rearrange the instructions as follows:
</p>
<p>
<code>lwz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r5,0(r3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;; Load value pointed to by r3 into r5</code><br>
<code>lwz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r6,0(r4)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;; Load value pointed to by r4 into r6</code><br>
<code>addi&nbsp;&nbsp;&nbsp;&nbsp;r5,r5,0x0005&nbsp;&nbsp;&nbsp;&nbsp;; Add 5 to value in r5</code><br>
<code>addi&nbsp;&nbsp;&nbsp;&nbsp;r6,r6,0x000a&nbsp;&nbsp;&nbsp;&nbsp;; Add 10 to value in r6</code>
</p>
<p class="spacer">&nbsp;</p>
<p>
Now look at what happens to the instruction pipeline (Figure 6): there are no delays.<br>
By moving the add instructions to later in the instruction stream, you allow the load<br>
instructions they depend on to complete, so the add instructions can execute<br>
immediately. 
</p>
<p>
<img src="img/278.gif" width="449 px"></img>
</p>
<p>
<b>Figure 5 </b>Stalled Pipelined Execution
</p>
<p>
<img src="img/279.gif" width="368 px"></img>
</p>
<p>
<b>Figure 6 </b>No-Delay Pipelined Execution
</p>
<p>
<b>BRANCHING</b><br>
All pipelined architectures face the problem of branches. Any time a conditional<br>
branch is encountered, the processor faces a dilemma because now two instruction<br>
streams are possible. It can't pipeline both possible paths. It can guess which path to<br>
take, but if it guesses wrong, the pipeline is disrupted. 
</p>
<p>
One common approach to this problem is a technique called <i>delayed branching</i>.&nbsp;&nbsp;In<br>
delayed branching, the processor <i>always</i> executes the instruction immediately following<br>
the branch instruction. While starting this instruction, the CPU can be figuring out<br>
the destination of the branch instruction and so can keep the pipeline flowing. Of<br>
course, it's important that the instruction after the branch not affect the branch. It's<br>
up to the compiler to find an instruction unrelated to the branch instruction to fill this<br>
delay slot. If it can't fill the delay slot, the compiler can always put in a no-op<br>
instruction, but this is inefficient. Some architectures allow the instruction in the<br>
delay slot to be ignored if the branch is taken. This avoids the need to fill the delay slot<br>
with a no-op instruction, but undermines the purpose of delayed branching. PowerPC<br>
architecture takes a unique approach to the branching problem, as discussed later in<br>
the section "Branch Processor."
</p>
<p>
<b>SUPERSCALAR DESIGN</b><br>
Another technique RISC designers use to increase performance is superscalar or<br>
multi-issue design.&nbsp;&nbsp;&nbsp;The simpler design of RISC architectures makes it possible to<br>
build in multiple processing units; this is superscalar design. In the same way that the<br>
compiler can juggle instructions to avoid resource constraints, the CPU can now<br>
reduce bottlenecks and achieve higher performance by feeding instructions to separate<br>
processing units operating in parallel. This allows average instruction cycle times to<br>
drop below one cycle per instruction. PowerPC microprocessors use this technique as<br>
discussed later in the section "Functional Units of the PowerPC Microprocessor."
</p>
<p>
<b>RISC ADVANTAGES</b><br>
One last point needs to be made before leaving a comparison of CISC and RISC. Many of<br>
the techniques used by RISC designers can and are used by CISC designers. Modern CISC<br>
chips such as the MC68040 and Intel 80486 make extensive use of instruction<br>
pipelining, parallel integer and floating-point units, fast cache architectures, and<br>
resource constraint reduction (such as delayed writes) to achieve the performance<br>
they do. But the sheer complexity of the designs means they're hard to implement (and<br>
implement correctly), which often results in long development cycles. The simplicity<br>
of RISC architecture helps avoid this problem. 
</p>
<p>
Similarly, the compiler can aid CISC machine performance. But the complexity of CISC<br>
design means it's nearly impossible to determine instruction timing, so it's difficult<br>
for the compiler to choose the best instruction sequence. Instruction scheduling is also<br>
possible but more difficult. The finer granularity of the RISC instruction set gives the<br>
compiler much more flexibility and control over the resources provided by the CPU. 
</p>
<p>
Simplified hardware and the influence of the compiler are really the ultimate<br>
advantages of RISC. 
</p>
<h2>POWERPC CPU ARCHITECTURE</h2>
<p>
PowerPC architecture is a modern 64-bit, RISC architecture adhering to all the<br>
previously discussed design goals. It has 32 general-purpose and 32 floating-point<br>
registers. All instructions have a uniform 32-bit length. The first PowerPC<br>
microprocessor, the PowerPC 601, is a superscalar implementation of the 32-bit<br>
subset of this architecture. 
</p>
<p>
<b>POWERPC VERSUS POWER</b><br>
The PowerPC microprocessor is a single-chip design descended from an earlier,<br>
multichip IBM RISC implementation known as POWER. It's worth mentioning the<br>
differences between the two architectures. 
</p>
<ul>
<li>Misaligned data access. Most RISC architectures require all data access to<br>
be word (4-byte) aligned. POWER was ambiguous regarding data alignment.<br>
PowerPC architecture explicitly allows misaligned data access but with a<br>
possible performance penalty. The advantage is that it allows use of data<br>
structures aligned for 680x0 architecture. </li>
<li>Elimination of the MQ register. POWER has a special-purpose<br>
multiply/quotient (MQ) register for extended-precision integer arithmetic.<br>
But since there's only one register, it becomes a bottleneck that hinders<br>
superscalar implementations. The MQ register, and all instructions that<br>
depend on it, were eliminated from the PowerPC architecture. </li>
<li>Addition of single-precision floating point. POWER supports only double-<br>
precision floating point. PowerPC architecture supports single precision as<br>
well, which may be more appropriate for some applications. (There's no<br>
hardware support for 80- or 96-bit extended floating point, which 680x0<br>
developers are familiar with. The consequences of this for developers are<br>
discussed in "Native PowerPC Numerics.")</li>
<li>64-bit architecture. POWER is a 32-bit architecture. PowerPC<br>
architecture is fully 64 bit; however, the first implementations feature a<br>
32-bit subset of the architecture. Code written for 32-bit processors will be<br>
fully supported on 64-bit implementations running in 32-bit mode.</li>
</ul>
<p>
PowerPC architecture uses big-endian byte order, just like 680x0 and POWER. As an<br>
added feature, it also supports a mode using little-endian byte ordering and provides<br>
instructions to allow access to little-endian data from big-endian mode and to<br>
big-endian data from little-endian mode. 
</p>
<p>
For divisible integer quantities composed of separately addressable bytes -- for<br>
example, a 32-bit integer subdivided into four addressable bytes -- there are<br>
numerous ways to arrange the bytes. Only two arrangements make sense and are in use<br>
on computers today. Big-endian byte ordering means the most significant byte (the big<br>
end of the number) is assigned the lowest address. Little-endian byte ordering means<br>
the least significant byte is assigned the lowest address; it's used, for example, on Intel<br>
80x86 CPUs. The terms originated in Jonathan Swift's&nbsp;&nbsp;Gulliver's Travels, where the<br>
controversy was over breaking an egg at the big end or the small end. *
</p>
<h2>FUNCTIONAL UNITS OF THE POWERPC MICROPROCESSOR</h2>
<p>
Figure 7 is a block diagram of the PowerPC 601 microprocessor, the first member of<br>
the PowerPC processor family. This microprocessor is a superscalar PowerPC<br>
implementation, with three separate execution units: the fixed-point and<br>
floating-point units and the branch processor. The branch processor initiates<br>
instruction execution by fetching instructions from the instruction cache (which is<br>
filled from memory if there are no instructions in it). The branch processor then<br>
feeds integer and floating-point instructions to the fixed-point and floating-point<br>
units respectively. These units operate on data in registers and in the data cache<br>
(which is filled from memory if there's no data in it). The fixed-point unit is also<br>
involved in address decode operations. 
</p>
<p>
<b>BRANCH PROCESSOR</b><br>
The branch processor deserves special attention. As mentioned earlier, PowerPC<br>
architecture takes an original approach to the problem of branch penalties, and the<br>
branch processor is responsible for this. The branch processor contains within it<br>
everything needed to determine how to handle a branch instruction. This includes three<br>
special-purpose registers:
</p>
<ul>
<li>The condition register (CR) has flags set by certain operations and is used<br>
for conditional branching. </li>
<li>The link register (LR) can contain a destination address for a branch<br>
instruction and can also hold the return address after branch and link<br>
(subroutine) instructions. </li>
<li>The count register (CTR) is used for looping and indirect branches. </li>
</ul><p><img src="img/281.gif" width="423 px"></img></p><p><b>Figure 7 </b>Block Diagram of PowerPC 601 Chip</p>
<p>
For unconditional branches, the branch processor knows unambiguously which path to<br>
take. For conditional branches, if a branch condition is set far enough before the actual<br>
branch instruction, the branch processor has the information necessary to determine<br>
which path to take.&nbsp;&nbsp;&nbsp;The design of the condition register uniquely aids the processing of<br>
conditional branches. Instead of a single set of condition codes, it contains eight 4-bit<br>
condition code fields, designated CR0, CR1 . . .&nbsp;&nbsp;&nbsp;CR7. Compare operations allow each<br>
field to be set independently. A compiler using these multiple, independent condition<br>
code fields has more flexibility in scheduling instructions to assist the branch<br>
processor. As an additional performance enhancement, instructions that might set<br>
condition codes (such as <b>add</b>) do so only if a record bit is set in the instruction, so time<br>
isn't spent setting condition codes that would otherwise be ignored. 
</p>
<p>
The branch processor also has knowledge of the count register, used in looping<br>
operations. This lets the branch processor know in advance when a loop will finish. 
</p>
<p>
With this design the branch processor can preprocess the instruction stream and, in<br>
most cases, determine in advance the target of the branch operation. This allows it to<br>
"fold" the branch instruction out of the instruction stream, so the fixed-point and<br>
floating-point units see an unbroken stream of instructions and fewer branch<br>
penalties occur. 
</p>
<h2>POWERPC RUNTIME ARCHITECTURE</h2>
<p>
An important goal in the development of Apple's PowerPC processor-based machines<br>
was to preserve user and developer investment in the 680x0 architecture. Another<br>
important goal was to port the existing 680x0 Toolbox and operating system to the new<br>
platform quickly. Both goals were met through the ability to emulate 680x0<br>
instructions in software on the PowerPC microprocessor.&nbsp;&nbsp;&nbsp;So the first way to view a<br>
Macintosh on PowerPC, and indeed the way existing applications and system software<br>
view this machine, is as a 680x0-based Macintosh. In this section we approach this<br>
new beast through the 680x0 emulator and then peel away the layers to reveal the<br>
underlying PowerPC runtime architecture. 
</p>
<p>
<b>SOFTWARE EMULATOR</b><br>
The software emulator understands and executes the instruction set of a Motorola<br>
MC68020 processor. You might wonder why Apple chose to emulate the MC68020 and<br>
not the latest and greatest processors such as MC68030 and MC68040.
</p>
<ul>
<li>The only advantage of the 68030 over the 68020, in terms of instruction<br>
set, is the integrated memory management unit (MMU). The MMU is really for<br>
use by the operating system for implementing features such as virtual<br>
memory. The PowerPC microprocessor MMU operation is very different from<br>
680x0 MMU operation, and there's no need for applications to execute MMU<br>
instructions anyway. Applications needing control over virtual memory can<br>
still use the existing virtual memory interface; just the implementation will<br>
be different. </li>
<li>Similarly, the key advantage of the MC68040 over its predecessors is the<br>
integrated floating-point unit. The PowerPC microprocessor has its own<br>
floating- point implementation. Apple already provides a standard numeric<br>
interface for 680x0 applications, called SANE, and emulating floating-point<br>
instructions using native PowerPC code offers no real advantages over<br>
implementing SANE as native PowerPC code. </li>
</ul>
<p>
As a bonus feature, the emulator also supports certain advanced user-mode<br>
instructions such as the MOVE16 instruction from the MC68040. However, from a<br>
programmer's point of view, the emulator behaves as an MC68020 (for example,<br>
Gestalt reports an MC68020 is present) and developers are advised not to take<br>
advantage of any features outside the MC68020 architecture. 
</p>
<p>
Once the emulator was up and working, the PowerPC processor-based machine almost<br>
immediately gained an operating system, since all the code in the ROM and the<br>
operating system was now executable. This also gave the machine a high degree of<br>
compatibility with older Macintosh models, because the same code, with all its<br>
idiosyncrasies, is being executed. 
</p>
<p>
Had Apple stopped here, you'd have a machine that works great but is pretty boring.<br>
After all, who wants a machine that pretends to execute 680x0 code, but not<br>
necessarily as fast as the real thing?&nbsp;&nbsp;Why not get a real 680x0 machine instead? The<br>
answer, of course, lies in tapping into the power behind the emulator -- the PowerPC<br>
microprocessor itself.
</p>
<p>
<b>TOOLBOX ACCELERATION</b><br>
All Macintosh applications spend part of their time calling the Macintosh Toolbox. In<br>
turn, the Toolbox performs the requested service by executing Toolbox code on behalf<br>
of the application. You can think of the Toolbox as an extension of the application. The<br>
advantage of this during development of PowerPC processor-based machines is that<br>
selectively replacing portions of the Toolbox with equivalent PowerPC code greatly<br>
enhances the performance of those portions of the Toolbox. All applications that use<br>
those routines benefit from improved performance. No modification of the application<br>
is required to receive the benefit. 
</p>
<p>
Ideally, of course, it would be best if the entire Toolbox executed as native code. But<br>
that requires a huge amount of work and would delay the first release of Macintosh on<br>
PowerPC. Analysis of application programs revealed that some portions of the Toolbox<br>
are used more heavily than others.&nbsp;&nbsp;&nbsp;All applications, for example, rely heavily on<br>
QuickDraw. Effort spent porting QuickDraw would benefit more applications than, say,<br>
porting the Dialog Manager. So the first release of Macintosh on PowerPC will target<br>
the portions of the Toolbox that will provide the greatest performance enhancement to<br>
the greatest number of applications. 
</p>
<p>
As Apple releases new versions of the system, with more and more of the Toolbox as<br>
native PowerPC code, users will magically get a "faster" machine without adding new<br>
hardware. All they have to do is install the newer, accelerated Toolbox. 
</p>
<p>
At the same time, the goal is not just to enhance the performance of the system, but to<br>
empower application software as well. The accelerated Toolbox is a start, but real<br>
PowerPC application performance comes from having native PowerPC applications,<br>
and the first release of Macintosh on PowerPC will include an entirely new runtime<br>
architecture in support of native applications. 
</p>
<p>
<b>WHY A NEW RUNTIME ARCHITECTURE?</b><br>
The new runtime architecture addresses many of the following limitations of the<br>
680x0 architecture:
</p>
<ul>
<li>The first Macintosh models were severely limited in the memory<br>
available to applications, so the runtime architecture was designed to squeeze<br>
the most out of the memory that was available. Today, the relative availability<br>
of cheap RAM removes this limitation. </li>
<li>Hard disks and memory management units required to support virtual<br>
memory were unavailable, so applications were required to load discrete<br>
blocks of code through the Segment Loader. With the relative availability of<br>
cheap RAM and support for virtual memory, most reasons for having the<br>
Segment Loader disappear.</li>
<li>The system now supports a wide variety of code types -- not just<br>
applications and system software, but standalone code blocks, such as INITs<br>
and MDEFs, and loadable code plug-ins, such as XCMDs and components. These<br>
code blocks strain the runtime architecture because it's difficult to manage<br>
global data for these blocks and to import and export functions between blocks.</li>
<li>There's a large amount of code duplication in the Macintosh. The Toolbox<br>
provides some code sharing between applications, but in general, most<br>
applications have built into them large amounts of redundant code. For<br>
example, library and glue code gets linked into every application. Having it<br>
built into the application increases demands on disk and memory resources<br>
because each instance of the application must have the duplicated code. </li>
</ul>
<p>
<b>CODE FRAGMENT MANAGER</b><br>
The centerpiece of the new architecture is the Code Fragment Manager. Each block of<br>
executable PowerPC code is a code fragment. A code fragment is autonomous, with its<br>
own static data. It can export both code and data references for use by other fragments<br>
and import code and data references from other fragments for its own use. Because such<br>
references are resolved at run time, code fragments are a form of dynamically linked,<br>
shared libraries. (See "Code Fragment Manager or Shared Library Manager?" for an<br>
explanation of the relationship between the two managers.)
</p>
<p>
From a native PowerPC application's point of view, access to the Macintosh Toolbox<br>
now occurs through a shared library maintained by the Code Fragment Manager.<br>
Applications no longer have segments -- they have one or more code fragments. The<br>
main code fragment is loaded at launch time and any external references to other<br>
shared libraries are resolved. An application neither knows nor cares whether a<br>
reference is internal or external; access is completely transparent. 
</p>
<p>
In some cases applications may want to manage code fragments on their own. For<br>
example, standalone code resources can now be handled as code fragments. This makes<br>
code resources such as XCMDs much easier to develop. Not only does such a resource<br>
have its own static data, but function references within the resource are fully<br>
exportable. Complicated parameter blocks aren't needed for passing data or jumping<br>
into the beginning of a code resource. Furthermore, because the application code is<br>
itself a code fragment and can export its references, the standalone code has access to<br>
functions and data within the application itself. Complicated callback mechanisms are<br>
no longer necessary. 
</p>
<h2>CODE FRAGMENT MANAGER OR SHARED LIBRARY MANAGER?</h2>
<p>
You may already be familiar with an implementation of shared libraries for the<br>
Macintosh known as the Shared Library Manager. The advantage of the Shared Library<br>
Manager is that it works with today's 680x0 runtime architecture. The Code Fragment<br>
Manager, on the other hand, lays the foundation for a new and more modern runtime<br>
architecture.
</p>
<p>
The first releases of these two managers will be mutually exclusive. The Shared<br>
Library Manager will be implemented only for 680x0 and the Code Fragment Manager<br>
will work only on the PowerPC microprocessor.
</p>
<p>
In the future, though, the Code Fragment Manager will be available on 680x0-based<br>
machines as well, and a future release of the Shared Library Manager (version 2.0)<br>
will be built on top of the Code Fragment Manager. This will provide Shared Library<br>
Manager support for Macintosh on PowerPC. Developers should code for whichever<br>
mechanism best suits their needs and target platform.
</p>
<p>
<b>MIXED MODE MANAGER</b><br>
There's one final piece to the PowerPC architecture puzzle. The Macintosh Toolbox<br>
makes wide use of pointers to functions. FilterProcs, I/O completion routines, A-trap<br>
vectors, QuickDraw bottlenecks, definition procedures (such as MDEFs, MBDFs, and<br>
CDEFs), and other types of standalone code (such as INITs and VBL tasks) are just a<br>
few examples of the wide variety of function pointers in use on the Macintosh.
</p>
<p>
On a 680x0-based Macintosh, life is easy because a function pointer is just the<br>
address of a 680x0 routine that can be called. On a PowerPC processor-based<br>
Macintosh, life is much more complicated; not only is the Toolbox a mixture of 680x0<br>
and PowerPC code, but a function pointer could be a pointer to 680x0 code or PowerPC<br>
code and the caller should neither know nor care what kind of code it's calling. 
</p>
<p>
To handle this situation, Apple is introducing the Mixed Mode Manager. One problem<br>
that this manager must solve is the mismatch between calling conventions for 680x0<br>
and PowerPC code.&nbsp;&nbsp;&nbsp;PowerPC code follows C conventions, with parameters passed right<br>
to left. The 680x0 code uses a variety of calling conventions: some traps are register<br>
based while some are Pascal stack based with parameters passed left to right. The<br>
Mixed Mode Manager must make calls between disparate functions seamless.<br>
Furthermore, it must do it in a way that's compatible with existing 680x0<br>
applications. Since existing binaries must work unmodified, the existence of the Mixed<br>
Mode Manager must be completely transparent to these applications.&nbsp;&nbsp;&nbsp;The Mixed Mode<br>
Manager's task is shown in Figure 8. Instead of passing a function pointer of type<br>
ProcPtr to the Toolbox, applications must now pass a function pointer of type<br>
UniversalProcPtr.&nbsp;&nbsp;&nbsp;UniversalProcPtr is a generic version of ProcPtr that lets the<br>
Mixed Mode Manager know how to route the call. Whenever 680x0 or PowerPC code<br>
calls a function through a UniversalProcPtr, the Mixed Mode Manager looks at the<br>
destination for the call. If a mode switch isn't necessary -- in other words, if both the<br>
caller and the callee are the same code type -- the Mixed Mode Manager does nothing<br>
and just passes the call to the caller. 
</p>
<p>
<img src="img/280.gif" width="534 px"></img>
</p>
<p>
<b>Figure 8 </b>Mixed Mode Manager
</p>
<p>
If a mode switch is necessary -- in other words, if a 680x0 caller is calling PowerPC<br>
code, or vice versa -- the Mixed Mode Manager performs a protocol conversion,<br>
rearranging the parameters, including moving them into or out of registers as<br>
necessary to ensure that the callee sees the parameters correctly. When the callee<br>
returns, the Mixed Mode Manager performs a protocol conversion in the other<br>
direction to ensure that return values are correctly passed back to the caller. 
</p>
<p>
For 680x0 applications, the Mixed Mode Manager is completely transparent and these<br>
applications run without modification. PowerPC applications, however, must become<br>
aware of the Mixed Mode Manager. The basics of using the Mixed Mode Manager are<br>
covered along with UniversalProcPtrs later in the section "UniversalProcPtrs."
</p>
<h2>WRITING PORTABLE C CODE</h2>
<p>
The preferred development languages for PowerPC code are C and C++. Therefore, the<br>
first step in preparing for the PowerPC platform is to provide portable C and C++<br>
code. The examples here use C, but the principles apply to C++ as well. 
</p>
<p>
The compilers for PowerPC C code are stricter than either the MPW or the THINK C<br>
compiler, so the best way to prepare your code for the PowerPC platform is to be sure<br>
it follows the ANSI C standard. You should take full advantage of the stronger type<br>
checking and prototyping features an ANSI C compiler provides. 
</p>
<p>
Consistent use of function prototypes is the best way to ensure portable code. ANSI C<br>
prototypes fully qualify the parameters to a function, as shown in this example:
</p>
<p>
<code>void DoEvent (EventRecord *event);</code>
</p>
<p>
It's usually permissible to mix the new-style function declaration with the old-style<br>
function definition:
</p>
<p>
<code>void DoEvent (event)</code><br>
<code>EventRecord *event;{ . . .</code><br>
<code>}</code>
</p>
<p>
However, mixing function declarations in this way typically defeats the purpose of<br>
having a function prototype in the first place. So the first step in writing portable code<br>
is to be sure you consistently use ANSI C function prototypes throughout. 
</p>
<p>
<b>INTEGERS AND BITFIELDS</b><br>
Variations in the size of integers of type int always cause trouble when you're trying<br>
to port code.&nbsp;&nbsp;&nbsp;This is more of a problem for THINK C code, which allows 16-bit<br>
integers of type int. C purists may not agree, but my recommendation is never to use<br>
type int. Always use integers of types short and long (or an equivalent type). The<br>
Macintosh Toolbox itself is explicit about data sizes, and experience has shown that<br>
developers dependent on the THINK C 16-bit integers of type int have more difficulty<br>
porting to the PowerPC platform. 
</p>
<p>
A similar caution applies to bitfields. Bitfields are useful for access to<br>
machine-dependent data structures and the like, but are inherently implementation<br>
defined and therefore nonportable.
</p>
<p>
<b>DATA STRUCTURES</b><br>
Some compilers allow incomplete arrays as the last member in a data structure:
</p>
<p>
<code>struct QElem {</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;struct QElem*qLink;</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;short qType;</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;short qData[];</code><br>
<code>};</code>
</p>
<p>
This isn't allowed by the ANSI C standard. Here's a more portable definition:
</p>
<p>
<code>struct QElem {</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;struct QElem*qLink;</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;short qType;</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;short qData[1];</code><br>
<code>};</code>
</p>
<p>
Similarly, some compilers allow comparison of data structures. Again, this isn't<br>
allowed by the ANSI C standard, so attempting to do something as simple as comparing<br>
two Rects will fail on the compilers for PowerPC code. 
</p>
<p>
When using data structures, you need to be aware of data alignment. RISC machines<br>
prefer (and often require) that data be aligned on a 4-byte boundary. But on the<br>
680x0, the default is to align data to a 2-byte boundary. PowerPC architecture<br>
specifically allows misaligned data access, but there can be a small performance<br>
penalty if multiple bus cycles are required for access to the data. This creates a<br>
dilemma: portability versus performance.
</p>
<p>
Because the Macintosh Toolbox relies on 680x0 data structures, data passed to the<br>
Toolbox must have 680x0 alignment. The same applies if you want to share data with<br>
680x0 applications. To solve this, the compiler now allows you, through #pragma<br>
statements and compiler options, to align PowerPC code data structures just like<br>
680x0 code data structures. But if the structure is only internal to your application,<br>
you probably want to use the natural PowerPC code alignment.&nbsp;&nbsp;&nbsp;Although it's likely to<br>
be painful to modify existing data structures for PowerPC code alignment, if you're<br>
designing new data structures, you can keep the alignment issue in mind and create<br>
structures that are optimal for both 680x0 and PowerPC processor-based machines. 
</p>
<p>
<b>COMPILER EXTENSIONS</b><br>
In addition to supporting 680x0 data alignment, compilers for PowerPC code have<br>
been extended in several other ways to make porting easier. This involves supporting<br>
several of the MPW C compiler extensions and features:
</p>
<ul>
<li> The compiler understands "\p" at the start of a string for the generation<br>
of Pascal strings. </li>
<li> The <b>pascal</b> function keyword is allowed by the compiler, but ignored. A<br>
subtle consequence of this is discussed in the section "Pascal Functions."</li>
<li> The compiler won't complain if you use C++ style line-end comments<br>
(//). </li>
<li> MPW C packs enums into the smallest data type possible and the<br>
compilers for PowerPC code have been extended to support the feature. </li>
</ul>
<p>
How can you tell if your code is ANSI C compliant? You can eliminate many of the<br>
idiosyncrasies in your code by compiling it with multiple compilers. Code conditioned<br>
in this way is much more portable to the PowerPC platform than code dependent on a<br>
single compiler. So one of the best ways to prepare for the PowerPC platform is to<br>
make sure your code compiles and runs with both MPW C and THINK C. 
</p>
<h2>WRITING CODE FOR POWERPC</h2>
<p>
Some changes to the programming model are necessary for the development of<br>
PowerPC code.&nbsp;&nbsp;&nbsp;However, Apple tried to limit changes so as to make the transition to<br>
the PowerPC platform easier for developers (see "Universal Interfaces" to understand<br>
how these changes affect development for 680x0 platforms).
</p>
<p>
<b>COMPATIBILITY GUIDELINES</b><br>
Everything ever written about compatibility guidelines for the Macintosh applies to<br>
the Macintosh on PowerPC in spades. Here are some of the key points:</p><ul><li>The code must be<br>
32-bit clean. Most applications now satisfy this requirement, thanks to System 7, but<br>
it deserves reiterating because 24-bit mode will no longer be an option.</li><li> For the first<br>
release of Macintosh on PowerPC, access to low memory is allowed exactly as before.<br>
Direct access to low memory applies for both 680x0 and native PowerPC applications;<br>
however, a procedural interface is provided as part of the new API, and developers are<br>
strongly urged to begin using it for future compatibility. For example, CurDirStore is<br>
a commonly used low-memory global, and two new functions are defined to provide<br>
access to it:

<p>
<code>long LMGetCurDirStore (void);</code><br>
<code>void LMSetCurDirStore (long CurDirStoreValue);</code>
</p>

<p>
</li><li>Don't depend on undocumented data structures. Also, don't depend on alignment of data<br>
structures.&nbsp;&nbsp;Don't write data into code. In the past, this was often necessary because of<br>
limitations of the runtime architecture. Many of the reasons for doing it no longer<br>
exist with PowerPC architecture, so avoid it.&nbsp;&nbsp;</li><li>Beware of dependencies on<br>
floating-point data types (see "Native PowerPC Numerics," earlier in this article). </li><li>
Don't depend on the hardware. Not only is there no longer a 680x0 CPU present, but<br>
the I/O architecture can also change. Use programmatic interfaces to perform I/O. </li><li>
Don't depend on the 680x0 runtime model, which is very idiosyncratic.&nbsp;&nbsp;Fortunately,<br>
many of those idiosyncrasies were eliminated in the PowerPC runtime architecture,<br>
making your life easier but complicating the move from the 680x0 to this new<br>
architecture. 
</li></ul>
<p>
Some of these points are discussed in the following sections. 
</p>
<h2>UNIVERSAL INTERFACES</h2>
<p>
<b>BY DEAN YU</b>
</p>
<p>
As Apple takes the Macintosh experience to a new chip architecture, it becomes more<br>
important than ever to have portable source code. With that in mind, Apple has created<br>
a set of&nbsp;&nbsp;universal interface files, which are provided on this issue's CD. The same<br>
interface file -- for example, Windows.h -- can be used to compile any source file for<br>
a Macintosh on either a 680x0 or a PowerPC microprocessor. The main changes you'll<br>
find in the C universal interface files are described below.
</p>
<p>
<b>All system software routines declared extern. </b>On the PowerPC platform, all<br>
routines can potentially be in a shared library, so all routines must be declared extern<br>
in order for the compiler to generate the correct code. Declaring routines extern is<br>
also compatible with MPW C.
</p>
<p>
<b>Inline code wrapped in macro definitions. </b>Obviously, 680x0 inline code isn't<br>
very useful on a PowerPC platform. 680x0 inline code is isolated by macros such as<br>
THREEWORDINLINE, which are defined in ConditionalMacros.h. These macros expand to<br>
inline initializers when compiling for 680x0 on non-shared library based platforms,<br>
and do nothing when compiling for PowerPC or shared library-based platforms.
</p>
<p>
<b>UniversalProcPtrs. </b>As discussed more fully in this article, the biggest change in<br>
the interface files is the introduction of the UniversalProcPtr data type used by the<br>
Mixed Mode Manager. In support of cross-platform code generation, the interface files<br>
define special "New" and "Call" macros (such as NewGrowZoneProc and<br>
CallGrowZoneProc) that hide the implementation details of using UniversalProcPtrs.<br>
For example, when you compile your application as 680x0 code, the Call macros jump<br>
to the routine pointed to by the UniversalProcPtr directly rather than invoke<br>
CallUniversalProc as they would for PowerPC compilation. Note that 680x0 versions<br>
of the Call macros are provided only for stack-based ProcPtrs.
</p>
<p>
<b>Low memory access. </b>To isolate dependencies on low memory, the SysEqu.h file has<br>
been removed and replaced by LowMem.h, which defines accessor functions for low<br>
memory. Previously defined accessor functions, such as MemError, are still defined<br>
but call through to the new accessor functions when appropriate.
</p>
<p>
<b>Structure alignment. </b>To maintain data structure compatibility, structs follow<br>
680x0 word alignments when being compiled for the PowerPC microprocessor.
</p>
<p>
Even if you don't plan on porting your application immediately to the PowerPC<br>
platform, you can begin using the universal interface files for 680x0 development and<br>
make a crucial step toward future PowerPC compatibility.
</p>
<p>
<b>REVISITING THE CODE FRAGMENT MANAGER</b><br>
As previously mentioned, the centerpiece of the PowerPC runtime architecture is the<br>
Code Fragment Manager. Rather than having a collection of code resources, a PowerPC<br>
application has a code fragment (generally one, but possibly more) that lives in the<br>
data fork of the application. When an application is launched, the Process Manager<br>
determines whether a native PowerPC code fragment is present by looking for a 'cfrg'<br>
resource. This resource provides the necessary information for the Code Fragment<br>
Manager to load the main code fragment and resolve any external code and data<br>
references. The Code Fragment Manager also sets up global data for the code fragment. 
</p>
<p>
The Code Fragment Manager eliminates the need for a segment loader. If virtual<br>
memory isn't present, the Code Fragment Manager loads the entire code fragment into<br>
memory; otherwise, it relies on virtual memory to page code directly in from the<br>
application when needed. 
</p>
<p>
A 680x0 application maintains a notion of an A5 world, an integral part of the 680x0<br>
runtime environment. Register A5 provides access to four kinds of data:
</p>
<ul>
<li>application global data</li>
<li>application QuickDraw global variables</li>
<li> application jump table</li>
<li> application parameters</li>
</ul>
<p>
Of these, only the QuickDraw global variables remain relevant. A wide variety of<br>
system and application code depends on using A5 to locate QuickDraw globals. Even<br>
though a native application has no use for a 680x0 register A5, the system still<br>
maintains an A5 world so that code that does depend on A5 has access to the right data.<br>
This means SetCurrentA5 and SetA5 will do the right thing with QuickDraw globals if<br>
you need to swap A5 worlds. 
</p>
<p>
The 680x0 Macintosh Toolbox uses a wide variety of calling conventions. The two most<br>
common ones are Pascal stack based and register based. Variations include passing a<br>
selector to dispatch to a variety of functions or passing a pointer to a parameter block<br>
in register A0 (for VBL tasks, notification tasks, and I/O completion routines) or<br>
register A1 (for Time Manager tasks). Two of my personal favorites are the TextEdit<br>
highHook and caretHook routines: when called they have a pointer to the edit record in<br>
A3 and, instead of a return address, a pointer to a rectangle on top of the stack. The<br>
point is that it's nearly impossible to write 680x0 Macintosh applications entirely in<br>
a high-level language. Some assembly-language programming is required just to move<br>
these weird parameters around. 
</p>
<p>
Life gets much easier on the PowerPC platform, which relies on uniform C calling<br>
conventions for everything. In almost all cases, 680x0 inline assembly and assembly<br>
wrapper routines can be rewritten in C for PowerPC code. For example, a 680x0<br>
application can use the following assembly highHook routine to underline a selection:
</p>
<p>
<code>HighHookUnderline</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;MOVE.L(SP),A0 ; Get the address of the rectangle</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;MOVE bottom(A0),top(A0); Make the top coordinate equal to</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;SUBQ #1,top(A0) ; the bottom coordinate minus 1</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;_InverRect ; Invert the resulting rectangle</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;RTS</code>
</p>
<p>
It's impossible to write this routine in C because of the weird calling conventions that<br>
supply the pointer to the Rect on top of the stack. For a native PowerPC application,<br>
the two parameters are simply specified as standard C parameters and the following<br>
routine suffices (the TEPtr parameter isn't used in this example):
</p>
<p>
<code>void HighHookUnderline (Rect *boundsRect, TEPtr pTE)</code><br>
<code>{ <br>&nbsp;&nbsp;&nbsp;&nbsp;boundsRect-&gt;top = boundsRect-&gt;bottom - 1;</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;InvertRect(boundsRect);</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;return;</code><br>
<code>}</code>
</p>
<p>
<b>PASCAL FUNCTIONS</b><br>
Although the compilers for PowerPC C code were extended to accept the <b>pascal</b> keyword<br>
for source code compatibility with 680x0 Macintosh code, when the compiler<br>
encounters this keyword, it does <i>absolutely nothing</i>. Unlike MPW C, where the keyword<br>
alters parameter ordering and changes how some parameters are passed, the compilers<br>
for PowerPC code ignore the <b>pascal</b> keyword. In most cases this is not a problem, but<br>
there can be some subtle consequences. For example, consider the following Apple<br>
event handler:
</p>
<p>
<code>pascal OSErr DoAEAnswer (AppleEvent message, AppleEvent reply,</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;long refCon);</code>
</p>
<p>
An Apple event record is larger than four bytes, so in Pascal it's automatically passed<br>
by reference.&nbsp;&nbsp;&nbsp;Because DoAEAnswer is declared as a <b>pascal</b> function, MPW C handles<br>
the parameter in the same way. But the compilers for PowerPC code treat it as a<br>
standard C data structure and pass it by value.&nbsp;&nbsp;&nbsp;So if DoAEAnswer were called by the<br>
Apple Event Manager, bizarre things would happen.&nbsp;&nbsp;</p><p>To be compatible with both types<br>
of compilers, you must explicitly make these parameters pointers, as follows:
</p>
<p>
<code>pascal OSErr DoAEAnswer (AppleEvent *message, AppleEvent *reply,</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;long refCon);</code>
</p>
<p>
When in doubt, check the new interfaces; they now declare special function pointers of<br>
type ProcPtr that specify the correct parameters. 
</p>
<p>
<code>typedef pascal OSErr (*EventHandlerProcPtr)(const AppleEvent</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;*theAppleEvent, const AppleEvent *reply, long handleRefCon);</code>
</p>
<p>
Unfortunately, in most cases you'll now be coercing any special ProcPtrs (such as<br>
EventHandlerProcPtr) into normal ProcPtrs for calls to NewRoutineDescriptor<br>
(described in the next section), which means type checking will be lost. So<br>
double-check all your callback routines. 
</p>
<p>
<b>UNIVERSALPROCPTRS</b><br>
Because of the introduction of the Mixed Mode Manager, the single biggest change you'll<br>
have to make to your code is converting function pointers of type ProcPtr to type<br>
UniversalProcPtr. Every place in the interfaces where a type of ProcPtr was declared,<br>
Apple added a similar declaration of type UniversalProcPtr.
</p>
<p>
UniversalProcPtr is a generic function pointer. For 680x0 code, a UniversalProcPtr<br>
is just a 680x0 ProcPtr. For native PowerPC code, though, a UniversalProcPtr is a<br>
pointer to a data structure called a <i>routine descriptor</i>, which in addition to providing a<br>
function reference, supplies all the information the Mixed Mode Manager needs to<br>
transform parameters back and forth between 680x0 and PowerPC worlds. Because a<br>
UniversalProcPtr is no longer a simple function reference, there are issues of<br>
allocation and scope that make it more complicated to use than a simple ProcPtr.&nbsp;&nbsp;<br>
Fortunately, 680x0 interfaces are being changed to add UniversalProcPtr support, so<br>
changes you make for PowerPC code will also be compatible with 680x0 interfaces<br>
(see "Universal Interfaces" earlier in this article). 
</p>
<p>
Let's look at a simple example using a UniversalProcPtr. Suppose you have an action<br>
procedure for a vertical scroll bar, called VActionProc. Current code would call<br>
TrackControl with that action procedure as follows:
</p>
<p>
<code>TrackControl(ctlHit, mouseLoc, VActionProc);</code>
</p>
<p>
With PowerPC code, you must create a routine descriptor for VActionProc. Because<br>
there's usually a one-to-one correspondence between function pointers of type<br>
ProcPtr in your code and function pointers of type UniversalProcPtr required by the<br>
Mixed Mode Manager, it's simplest to allocate one UniversalProcPtr for each ProcPtr<br>
you use. The memory impact of this approach is small because a routine descriptor<br>
data structure typically uses only 32 bytes. 
</p>
<p>
One way to do this is to allocate the routine descriptor statically and have it initialized<br>
by the compiler. Macros are supplied in MixedMode.h for this purpose. For example,<br>
you can create a routine descriptor for VActionProc like this:
</p>
<p>
<code>RoutineDescriptor gVActionProcRD =</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;BUILD_ROUTINE_DESCRIPTOR(uppControlActionProcInfo, VActionProc);</code>
</p>
<p>
Alternatively, you can allocate your routine descriptors on the heap. Again, because<br>
they seldom change, you'll generally want to allocate them at application startup:
</p>
<p>
<code>ControlActionUPPgVActionUPP;</code>
</p>
<p>
<code>gVActionUPP = NewRoutineDescriptor((ProcPtr)VActionProc,</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;uppControlActionProcInfo, GetCurrentISA());</code>
</p>
<p>
NewRoutineDescriptor is declared as follows:
</p>
<p>
<code>UniversalProcPtr NewRoutineDescriptor(ProcPtr theProc,</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;ProcInfoType theProcInfo, ISAType theISA);</code>
</p>
<p>
NewRoutineDescriptor allocates nonrelocatable storage for the routine descriptor on<br>
the heap and returns it as a pointer to the routine descriptor in the form of a<br>
UniversalProcPtr. The theProc parameter is just the function pointer for the function<br>
you're referring to and theProcInfo is a 32-bit value that tells the Mixed Mode<br>
Manager how to convert parameters back and forth. Every UniversalProcPtr type has<br>
defined for it a corresponding ProcInfoType value. So the ProcInfoType value for<br>
ControlActionUPP is uppControlActionProcInfo. The third parameter, theISA, specifies<br>
the current instruction set architecture (ISA) in use. For portable code, simply call<br>
GetCurrentISA to get the appropriate ISA type. If you know you're dealing with a<br>
specific code type -- for example, a 680x0 code resource -- you can call<br>
NewRoutineDescriptor and specify the proper instruction set type -- for example,<br>
kM68kISA for 680x0 code. 
</p>
<p>
To simplify creation of function pointers of type UniversalProcPtr, the new interfaces<br>
also define macros that call NewRoutineDescriptor for you and automatically specify<br>
the ProcInfoType value:
</p>
<p>
<code>gVActionUPP = NewControlActionProc((ProcPtr) VActionProc);</code>
</p>
<p>
If you created the routine descriptor statically, you can pass the address of the<br>
structure to TrackControl:
</p>
<p>
<code>TrackControl(ctlHit, mouseLoc, (ControlActionUPP) &amp;gVActionProcRD);</code>
</p>
<p>
If, instead, you created a UniversalProcPtr on the heap, you can use it directly in<br>
TrackControl:
</p>
<p>
<code>TrackControl(ctlHit, mouseLoc, gVActionUPP);</code>
</p>
<p>
If you allocate a UniversalProcPtr statically, you don't have to worry about<br>
deallocating it, because that will happen when the application quits. You could also<br>
allocate it locally, which you might want to do if the routine were unlikely to be called.<br>
In that case, you would have to explicitly deallocate the routine descriptor before<br>
leaving the function, as follows:
</p>
<p>
<code>DisposeRoutineDescriptor(gVActionUPP);</code>
</p>
<p>
A potential problem with disposing of routine descriptors is that you could dispose of<br>
them before they're used. For example, if you have a routine descriptor for an<br>
asynchronous I/O completion routine, disposing of the routine descriptor before the<br>
completion routine is called would be bad.
</p>
<p>
An alternative for infrequently used routine descriptors is to allocate them globally<br>
but initialize them only when needed, as in this example:
</p>
<p>
<code>if (!gVActionUPP)</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;gVActionUPP = NewControlActionProc((ProcPtr) VActionProc);</code><br>
<code>TrackControl(ctlHit, mouseLoc, gVActionUPP);</code>
</p>
<p>
In most cases you won't need to call a UniversalProcPtr yourself; you'll simply pass it<br>
to the Toolbox. But should you need to call one from PowerPC code, you can't simply<br>
treat it as a function pointer. You must use CallUniversalProc to have the Mixed Mode<br>
Manager call the function for you.&nbsp;&nbsp;&nbsp;CallUniversalProc is declared as follows:
</p>
<p>
<code>long CallUniversalProc(UniversalProcPtr theProcPtr,</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;ProcInfoType procInfo, ...);</code>
</p>
<p>
The first two parameters, the UniversalProcPtr and the 32-bit ProcInfoType value,<br>
are followed by all the additional parameters normally passed to the call. To simplify<br>
calling UniversalProcPtrs,special macros have been included in the interfaces for<br>
each UniversalProcPtr data type. For example, gVActionUPP above could be called<br>
using CallControlActionProc:
</p>
<p>
<code>CallControlActionProc(gVActionUPP, theControl, partCode);</code>
</p>
<p>
One special case of a UniversalProcPtr deserves mention because it can't be flagged by<br>
the compiler.&nbsp;&nbsp;&nbsp;A wonderful feature of the Dialog Manager is that for a userItem, the<br>
SetDItem call allows the item's procedure pointer to be set via the item parameter.<br>
Since you're explicitly casting a ProcPtr to a handle, the compiler assumes you know<br>
what you're doing and doesn't object. Of course, what you really need to pass is a<br>
UniversalProcPtr, but since the compiler doesn't catch this, strange things will<br>
surely happen if you don't catch it yourself. 
</p>
<p>
As another example of using function pointers of type UniversalProcPtr, let's look at a<br>
VBL task. A persistent VBL task (one that works when the application is in the<br>
background) is often implemented by copying the VBL task code into the system heap,<br>
an ugly solution and self-modifying code as well.&nbsp;&nbsp;&nbsp;A simpler solution for PowerPC code<br>
is to create the UniversalProcPtr itself in the system heap since the Process Manager<br>
views the UniversalProcPtr as code. The following code shows how to install such a<br>
VBL task:
</p>
<p>
<code>#define kVBLInterval 30</code>
</p>
<p>
<code>OSErr InstallVBL (VBLTaskPtr theVBLTask, VBLProcPtr myVBLProc,</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;Boolean isPersistent)</code><br>
<code>{ <br>&nbsp;&nbsp;&nbsp;&nbsp;OSErr theError;</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;THz&nbsp;&nbsp;savedZone;</code>
</p>
<p>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;*</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* For a VBL task that operates when the application is in the</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* background (i.e., that's persistent) we can simply create the</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* UniversalProcPtr in the system heap. This causes the Process</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* Manager to treat the code as though it were in the system heap</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* and the VBL will always get executed.</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* /</code>
</p>
<p>
<code>&nbsp;&nbsp;&nbsp;&nbsp;if (isPersistent) {</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;savedZone = GetZone();</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SetZone(SystemZone());</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;}</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;theVBLTask-&gt;vblAddr = NewRoutineDescriptor((ProcPtr) myVBLProc,</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;uppVBLProcInfo, GetCurrentISA());</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;theError = MemError();</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;if (isPersistent)</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SetZone(savedZone); /* Restore the application zone. */</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;if (theVBLTask-&gt;vblAddr != nil) {</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;theVBLTask-&gt;qType = vType;</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;theVBLTask-&gt;vblCount = kVBLInterval;</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;theVBLTask-&gt;vblPhase = 0;</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;theError = VInstall((QElemPtr) theVBLTask);</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;}</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;return (theError);</code><br>
<code>}</code>
</p>
<p>
The isPersistent Boolean variable controls whether the VBL functions persistently. If<br>
it's persistent, you can control where the memory is allocated by first setting the zone<br>
to the system zone (because NewRoutineDescriptor calls the Memory Manager to<br>
allocate memory for the routine descriptor). 
</p>
<p>
Here's the code for the VBL task:
</p>
<p>
<code>long gCounter = 0;</code>
</p>
<p>
<code>pascal void MyVBLProc (VBLTaskPtr theVBLTask)</code><br>
<code>{ <br>&nbsp;&nbsp;&nbsp;&nbsp;theVBLTask-&gt;vblCount = kVBLInterval;</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;gCounter++;</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;return;</code><br>
<code>}</code>
</p>
<p>
This very simple example alters only a global variable, but it illustrates two points.<br>
First, no complicated setup for global variables is required. For a 680x0 VBL task,<br>
messy saving and restoring of register A5 would be necessary for correct access to<br>
global variables. In the example, because the code resides in a code fragment, global<br>
variables are always accessible. Second, the procedure is called with a VBLTaskPtr<br>
parameter. For a 680x0 VBL task, a pointer to the VBLTask record resides in register<br>
A0 and requires special handling to get to the data from a high-level language. Because<br>
PowerPC code uses strict C calling conventions, the required data is passed as a<br>
standard parameter. 
</p>
<p>
Finally, of course, you have to remove the VBL task correctly:
</p>
<p>
<code>void RemoveVBL (VBLTaskPtr theVBLTask)</code><br>
<code>{ <br>&nbsp;&nbsp;&nbsp;&nbsp;THzsavedZone;</code>
</p>
<p>
<code>&nbsp;&nbsp;&nbsp;&nbsp;VRemove((QElemPtr) theVBLTask);</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;if (theVBLTask-&gt;vblAddr) {</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;savedZone = GetZone();</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* Make sure we're in the right zone. */</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SetZone(PtrZone((Ptr) theVBLTask-&gt;vblAddr));</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;DisposeRoutineDescriptor(theVBLTask-&gt;vblAddr);</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SetZone(savedZone);</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;}</code><br>
<code>&nbsp;&nbsp;&nbsp;&nbsp;return;</code><br>
<code>}</code>
</p>
<p>
Although it may not be necessary to deallocate a VBL task created in the application<br>
heap, this code practices safe memory management by being sure the memory gets<br>
deallocated no matter where it is -- in other words, whether it's persistent or not. 
</p>
<p>
<b>TRAP PATCHING</b><br>
Trap patching is fully supported on the PowerPC microprocessor; as always, however,<br>
it must be undertaken with due care and consideration. Not only is the compatibility<br>
risk higher (especially if you're dependent on 680x0 runtime features), but<br>
indiscriminate trap patching can severely affect the performance of the PowerPC<br>
processor-based machine. 
</p>
<p>
Trap patching is possible from both 680x0 code and PowerPC code, and you should use<br>
the NGetTrapAddress and NSetTrapAddress calls in both cases. From PowerPC code, the<br>
address returned by NGetTrapAddress must be treated as a UniversalProcPtr and you<br>
must pass a UniversalProcPtr to NSetTrapAddress as well. 
</p>
<p>
What complicates the issue is that the trap you patch could be written in either 680x0<br>
code or PowerPC code. The Mixed Mode Manager, of course, handles both cases, but if<br>
you're patching native PowerPC code with 680x0 code, performance-sensitive code<br>
can suddenly run more slowly, not only because of your emulated code but because of<br>
overhead associated with mixed mode transitions. So you must think very carefully<br>
about the performance consequences of your patch. 
</p>
<h2>TAKING A RISC</h2>
<p>
To ease the transformation of existing applications into native PowerPC applications,<br>
Apple has minimized changes to the API. Most ANSI C compliant code, with the<br>
exception of ProcPtrs, should recompile without modification. Developers can exploit<br>
this opportunity to easily tap into the power of the PowerPC microprocessor. 
</p>
<p>
With PowerPC processor-based machines, Apple is laying the foundation for the<br>
future. The new levels of performance and new features such as the Code Fragment<br>
Manager give developers new worlds to explore and new opportunities for adding<br>
unique features to their applications. 
</p>
<h2>NATIVE POWERPC NUMERICS</h2>
<p>
<b>BY ALI SAZEGARI</b>
</p>
<p>
Developers dependent on floating point who port to the PowerPC platform will enjoy<br>
superior floating-point performance. However, some special consideration is needed,<br>
because the floating-point implementation on the PowerPC processor differs from that<br>
of the 680x0 processors.
</p>
<p>
<b>POWERPC ARCHITECTURE FEATURES</b><br>
The PowerPC microprocessor floating point is an&nbsp;&nbsp;IEEE 754-compliant single- and<br>
double-precision implementation offering fast, pipelined, nondestructive<br>
floating-point operations. These operations are add, subtract, multiply, divide,<br>
compare, convert to int, and a new class of multiply-add fused (MAF) instructions of<br>
the form
</p>
<p>
<i>frT</i> &#8592; (<i>frA</i> * <i>frB</i>) + <i>frC</i>
</p>
<p>
where <i>fr</i> is a floating-point register. In MAF operations, all bits of the resultant<br>
multiply section are kept (106 bits in double) and participate in the final rounding,<br>
producing&nbsp;&nbsp;a more exact result. In other words, (<i>A</i> * <i>B</i>) + <i>C</i> is a single operation with<br>
one rounding. The compilers on&nbsp;&nbsp;the PowerPC platform use MAF instructions wherever<br>
possible, unless expressly prohibited by the user.
</p>
<p>
The PowerPC microprocessor has a rich set of floating-point register files: 32<br>
floating-point double-precision data registers and a combined status and control<br>
register (unlike the MC6888x or MC68040).
</p>
<p>
<b>C PROGRAMMER'S MODEL</b><br>
The PowerPC microprocessor shared math library, MathLib, complies with the<br>
emerging Floating-Point C Extensions (FPCE X3J11.1/93-001) of the Numerical C<br>
Extensions Group (NCEG) specification. FPCE extends C to provide access to<br>
floating-point features generally and IEEE 754/854 specifically. FPCE provides a<br>
superset of math.h and sane.h functionality. The new required include files are fp.h and<br>
fenv.h.
</p>
<p>
The FPCE fp.h file is a collection of mathematical functions. It defines all math.h and<br>
nonenvironmental sane.h functionality plus hyperbolic, inverse hyperbolic, max,<br>
min, positive difference, error, and gamma functions. Other functions round<br>
floating-point numbers to integral values or integral format. An extensive array of<br>
correctly rounded binary-to-decimal conversion functions is provided.
</p>
<p>
The FPCE fenv.h file defines all the functions used to query or modify the<br>
floating-point environment (exception flags and rounding direction).
</p>
<p>
The include file math.h is kept for ANSI C compliance, but developers are encouraged to<br>
use fp.h and fenv.h. The sane.h include file won't be supported.&nbsp;&nbsp;<i>Be aware of function<br>
name and prototype differences





between SANE and FPCE-NCEG interfaces.</i> <br>For example, the functions<br>
copysign and scalb have reversed arguments in the new fp.h, and log1 is now called<br>
log1p.
</p>
<p>
<b>FP DATA TYPES</b><br>
Table 1 lists the available native data types on the PowerPC microprocessor. There's<br>
no hardware or compiler support for the 80- or 96-bit IEEE extended values<br>
commonly used by Macintosh programmers. Developers should use 64-bit double as<br>
their native data type and use rescaling techniques within their algorithms susceptible<br>
to numerical ill-conditioning. The 64-bit comp type, a floating-point data type<br>
available on the 680x0-based Macintosh, isn't supported. Use the data type long double<br>
judiciously and only when an algorithm requires the extra precision. SANE data types,<br>
which include extended and comp, are fully supported in emulation mode on PowerPC<br>
processor-based Macintosh systems.
</p>
<p>
The transcendental long-double functions are not supported for the first release of<br>
MathLib on PowerPC processor-based Macintosh systems. A complete long-double<br>
library is planned for a later release.
</p>
<p>
&nbsp;<b>Table 1</b> Available Native Data Types on the PowerPC Microprocessor
</p>
        <p>
            <table border="0">
                <tr>
                    <td><b>Native Data Type</b></td>
                    <td><b>Description</b></td>
                </tr>
                <tr>
                    <td>float</td>
                    <td>IEEE single precision (32 bits with fast operations)</td>
                </tr>
                <tr>
                    <td>double</td>
                    <td>IEEE double precision (64 bits with fast operations)</td>
                </tr>
                <tr>
                    <td>long double</td>
                    <td>128-bit structure of two doubles (head and tail), whose value is head + tail. Not</td>
                </tr>
                <tr>
                    <td></td>
                    <td>an IEEE double-extended type! Provides additional precision within double range.</td>
                </tr>
            </table>
        </p>
        






<p>
&nbsp;<b>Note:</b> The long double data type isn't supported by the hardware, so operations are<br>
relatively slow. It should be used selectively.
</p>
<h2>RECOMMENDED READING</h2>
<p>
For more information on CISC and RISC architectures in general and POWER and<br>
PowerPC architectures in particular, consult the following sources:
</p>
<ul>
<li>Advanced Microprocessors by Daniel Tabak (McGraw-Hill, 1991).</li>
<li>Computer Architecture and Computer Architecture Case Studies by Robert<br>
J. Baron and Lee Higbie (Addison-Wesley, 1992).</li>
<li>Computer Architecture: A Quantitative Approach by David A. Patterson and<br>
John L. Hennessy (Morgan Kaufman Publishers, 1990).</li>
<li>"PowerPC Performs for Less," by Tom Thompson, Byte, August 1993.</li>
<li>"RISC Drives PowerPC," by Bob Ryan, Byte, August 1993.</li>
<li>PowerPC 601 RISC Microprocessor User's Manual (Motorola, 1993).</li>
</ul>
<p>
<b>DAVE RADCLIFFE</b> is a five-year veteran of Apple's Developer Technical Support group<br>
and for the past year has been excited to be part of the PowerPC project. When he's not<br>
plumbing the depths of MacsBug, Dave enjoys relaxing&nbsp;&nbsp;with a mug of beer from one of<br>
the local microbreweries, watching old movies at the Stanford Theatre, or just being a<br>
couch potato in front of one of his laser disc videos. For his sabbatical, Dave is looking<br>
forward to a low-tech adventure river rafting through the Grand Canyon.*
</p>
<p>
<b>THANKS TO OUR TECHNICAL REVIEWERS</b> C. K. Haun, Ron Hochsprung, Bruce Jones,<br>
Alan Lillich, Wayne Meretzky, Eric Traut*Thanks to Paul Finlayson and Stuart<br>
McDonald for their review of "Native PowerPC Numerics." *
</p>
</body>
</html>
